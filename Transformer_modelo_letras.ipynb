{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Z4X8i7DJkIMc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752599780448,"user_tz":240,"elapsed":123983,"user":{"displayName":"Matias soto uribe","userId":"03140738076259130257"}},"outputId":"1bba0476-469f-4357-805b-7c4428f8c7ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","source":["# Importaciones\n","\n","**PyTorch (torch, nn, DataLoader):** Para crear y entrenar redes neuronales.\n","\n","**numpy, pandas:** Para manejar y analizar datos numÃ©ricos y tablas.\n","re, string, math: Para trabajar con texto y operaciones matemÃ¡ticas.\n","\n","**collections:** Para contar y organizar datos fÃ¡cilmente.\n","\n","**warnings:** Para ocultar advertencias.\n","\n","**nltk:** Para procesar y dividir texto en palabras.\n","\n","**BLEU y ROUGE:** Para evaluar la calidad de textos generados por el modelo.\n","\n","**subprocess:** Para instalar paquetes automÃ¡ticamente si faltan."],"metadata":{"id":"49XJs7CDGSyb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lukrSIdSkJff"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import pandas as pd\n","import re\n","import string\n","import math\n","from collections import Counter, defaultdict\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Importaciones para mÃ©tricas\n","import nltk\n","from nltk.tokenize import word_tokenize, RegexpTokenizer\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","try:\n","    from rouge_score import rouge_scorer\n","except ImportError:\n","    import subprocess\n","    subprocess.check_call(['pip', 'install', 'rouge-score'])\n","    from rouge_score import rouge_scorer\n","\n","# Descargas necesarias de NLTK\n","for package in ['punkt', 'punkt_tab', 'wordnet']:\n","    try:\n","        nltk.download(package, quiet=True)\n","    except:\n","        pass\n","\n","# ConfiguraciÃ³n de evaluaciÃ³n\n","smooth_function = SmoothingFunction().method2\n","evaluador_rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)"]},{"cell_type":"markdown","source":["# DefiniciÃ³n de semilla reproductibilidad\n","\n","En este bloque se define y utiliza una funciÃ³n para establecer una semilla aleatoria fija en Python, NumPy y PyTorch. Esto asegura que los resultados de los experimentos sean reproducibles, es decir, que al ejecutar el cÃ³digo varias veces se obtengan los mismos resultados. TambiÃ©n se configuran opciones adicionales para garantizar el determinismo en los cÃ¡lculos y se fija la variable de entorno correspondiente.\n"],"metadata":{"id":"4vbQ11ggHpod"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1Hbmht90X_v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752599791883,"user_tz":240,"elapsed":20,"user":{"displayName":"Matias soto uribe","userId":"03140738076259130257"}},"outputId":"b7173e9d-c200-42a6-d064-1b2b9759a94c"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸŒ± Semillas establecidas para reproducibilidad (semilla=42)\n"]}],"source":["# Definir semilla antes de usarla\n","SEMILLA_ALEATORIA = 42\n","\n","def establecer_semilla_reproducibilidad(semilla=42):\n","    \"\"\"\n","    Establece semillas aleatorias para reproducibilidad completa\n","    \"\"\"\n","    # Python\n","    import random\n","    random.seed(semilla)\n","\n","    # NumPy\n","    np.random.seed(semilla)\n","\n","    # PyTorch\n","    torch.manual_seed(semilla)\n","    torch.cuda.manual_seed(semilla)\n","    torch.cuda.manual_seed_all(semilla)\n","\n","    # ConfiguraciÃ³n adicional para determinismo\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","    # Variables de entorno\n","    import os\n","    os.environ['PYTHONHASHSEED'] = str(semilla)\n","\n","    print(f\"ğŸŒ± Semillas establecidas para reproducibilidad (semilla={semilla})\")\n","\n","# Establecer reproducibilidad\n","establecer_semilla_reproducibilidad(SEMILLA_ALEATORIA)\n"]},{"cell_type":"markdown","source":["# DefiniciÃ³n de cada parametro de entrenamiento\n","\n","**DISPOSITIVO:**\n","Indica si se usarÃ¡ la GPU (\"cuda\") o la CPU para entrenar y ejecutar el modelo, dependiendo de la disponibilidad.\n","\n","**TAMAÃ‘O_LOTE (batch size):**\n","NÃºmero de ejemplos que se procesan juntos en cada paso de entrenamiento. Un valor mayor puede acelerar el entrenamiento, pero requiere mÃ¡s memoria.\n","\n","**DIM_EMBEDDING:**\n","DimensiÃ³n de los vectores de embedding, es decir, el tamaÃ±o de la representaciÃ³n numÃ©rica de cada palabra o token.\n","\n","**CABEZAS_ATENCION:**\n","NÃºmero de \"cabezas\" en la capa de atenciÃ³n mÃºltiple del Transformer. MÃ¡s cabezas permiten al modelo enfocarse en diferentes partes de la secuencia simultÃ¡neamente.\n","\n","**CAPAS_TRANSFORMER:**\n","Cantidad de capas (bloques) del modelo Transformer. MÃ¡s capas pueden aumentar la capacidad del modelo para aprender patrones complejos.\n","\n","**LONGITUD_MAXIMA:**\n","Longitud mÃ¡xima permitida para las secuencias de entrada o salida. Las secuencias mÃ¡s largas se recortan o rellenan hasta este tamaÃ±o.\n","\n","**DROPOUT:**\n","ProporciÃ³n de neuronas que se \"apagan\" aleatoriamente durante el entrenamiento para evitar el sobreajuste.\n","\n","**TASA_APRENDIZAJE (learning rate):**\n","Velocidad con la que el modelo ajusta sus parÃ¡metros durante el entrenamiento. Un valor adecuado es clave para un buen aprendizaje.\n","\n","**NUM_EPOCAS:**\n","NÃºmero de veces que el modelo recorre todo el conjunto de datos de entrenamiento.\n","\n","**FACTOR_GRAD_CLIP:**\n","LÃ­mite mÃ¡ximo para el valor de los gradientes durante el entrenamiento, evitando que sean demasiado grandes y causen inestabilidad.\n","\n","**UMBRAL_FRECUENCIA:**\n","Frecuencia mÃ­nima con la que una palabra debe aparecer en el corpus para ser incluida en el vocabulario del modelo."],"metadata":{"id":"BuJ_rUd7IF0V"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KbQWcYeskLFI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752599791957,"user_tz":240,"elapsed":34,"user":{"displayName":"Matias soto uribe","userId":"03140738076259130257"}},"outputId":"5ffd0386-9f22-45be-f305-89f39b6ef34a"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ Dispositivo de procesamiento: cuda\n","ğŸ“Š ConfiguraciÃ³n: 64 batch, 512 dim, 4 heads\n"]}],"source":["# === ParÃ¡metros del Sistema de GeneraciÃ³n ===\n","\n","# ConfiguraciÃ³n del hardware\n","DISPOSITIVO = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# HiperparÃ¡metros del modelo\n","TAMAÃ‘O_LOTE = 64\n","DIM_EMBEDDING = 512\n","CABEZAS_ATENCION = 4\n","CAPAS_TRANSFORMER = 3\n","LONGITUD_MAXIMA = 128\n","DROPOUT = 0.1\n","\n","# ParÃ¡metros de entrenamiento\n","TASA_APRENDIZAJE = 2e-4\n","NUM_EPOCAS = 45\n","FACTOR_GRAD_CLIP = 1.0\n","UMBRAL_FRECUENCIA = 3\n","\n","print(f\"ğŸš€ Dispositivo de procesamiento: {DISPOSITIVO}\")\n","print(f\"ğŸ“Š ConfiguraciÃ³n: {TAMAÃ‘O_LOTE} batch, {DIM_EMBEDDING} dim, {CABEZAS_ATENCION} heads\")"]},{"cell_type":"markdown","source":["#Clase Vocabulario\n","\n","Esta clase se encarga de construir y gestionar el vocabulario del modelo. Permite convertir palabras o sÃ­mbolos en Ã­ndices numÃ©ricos y viceversa, lo cual es esencial para que el modelo pueda trabajar con texto.\n","\n","__init__: Inicializa el diccionario y el tokenizador.\n","\n","__len__: Devuelve cuÃ¡ntos tokens hay en el diccionario.\n","\n","**construir_diccionario:** Crea el vocabulario a partir de textos, solo con palabras frecuentes.\n","\n","**procesar_texto:** Limpia y divide el texto en tokens.\n","\n","**convertir_a_indices:** Convierte un texto en una lista de nÃºmeros (Ã­ndices de tokens)."],"metadata":{"id":"0_xbk9pHIr8o"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6K89WIIkMPx"},"outputs":[],"source":["class DiccionarioTokens:\n","    def __init__(self, min_frecuencia=3):\n","        # Tokens especiales con diferentes sÃ­mbolos\n","        self.indice_a_token = {\n","            0: \"[PAD]\",\n","            1: \"[INICIO]\",\n","            2: \"[FIN]\",\n","            3: \"[DESCONOCIDO]\",\n","            4: \">>>\"\n","        }\n","        self.token_a_indice = {v: k for k, v in self.indice_a_token.items()}\n","        self.min_frecuencia = min_frecuencia\n","        self.tokenizador = RegexpTokenizer(r'\\w+|[^\\w\\s]+')\n","\n","    def __len__(self):\n","        return len(self.indice_a_token)\n","\n","    def construir_diccionario(self, lista_textos):\n","        contador_palabras = Counter()\n","        indice_actual = len(self.indice_a_token)\n","\n","        # Primera pasada: contar frecuencias\n","        for texto in lista_textos:\n","            tokens = self.procesar_texto(texto)\n","            contador_palabras.update(tokens)\n","\n","        # Segunda pasada: agregar palabras frecuentes\n","        for palabra, frecuencia in contador_palabras.items():\n","            if frecuencia >= self.min_frecuencia and palabra not in self.token_a_indice:\n","                self.token_a_indice[palabra] = indice_actual\n","                self.indice_a_token[indice_actual] = palabra\n","                indice_actual += 1\n","\n","    def procesar_texto(self, texto):\n","        # TokenizaciÃ³n personalizada con regex\n","        texto = texto.lower().strip()\n","        tokens = self.tokenizador.tokenize(texto)\n","        return [t for t in tokens if t and not t.isspace()]\n","\n","    def convertir_a_indices(self, texto):\n","        tokens = self.procesar_texto(texto)\n","        desconocido_idx = self.token_a_indice[\"[DESCONOCIDO]\"]\n","        return [self.token_a_indice.get(token, desconocido_idx) for token in tokens]"]},{"cell_type":"markdown","source":["# clase ConjuntoDatosReseÃ±as:\n","Esta clase prepara y organiza los datos de reseÃ±as para entrenar el modelo. Lee un archivo CSV con reseÃ±as y categorÃ­as, limpia los datos, construye el vocabulario necesario y convierte cada ejemplo en una secuencia de nÃºmeros (Ã­ndices de tokens). AdemÃ¡s, agrega tokens especiales, aplica padding para igualar la longitud de las secuencias y genera los pares de entrada y salida que necesita el modelo para aprender a predecir el siguiente token en una secuencia.\n","\n","\n","\n","*   __init__:\n","Carga los datos desde un archivo CSV, elimina filas vacÃ­as, crea el diccionario de tokens y prepara los textos combinando la categorÃ­a y la reseÃ±a.\n","\n","* __len__:\n","Devuelve cuÃ¡ntos ejemplos hay en el conjunto de datos.\n","\n","\n","*  __getitem__:\n","Toma una fila, la convierte en texto, la tokeniza y la transforma en una secuencia de Ã­ndices con tokens especiales. Aplica padding y prepara los tensores de entrada y salida para el modelo.\n","\n","\n","\n","\n"],"metadata":{"id":"LzsCWmJjJnAB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_Ayo4R9kOdK"},"outputs":[],"source":["class ConjuntoDatosReseÃ±as(Dataset):\n","    def __init__(self, archivo_csv, longitud_max=LONGITUD_MAXIMA):\n","        # Cargar y preparar datos\n","        self.datos = pd.read_csv(archivo_csv)\n","        self.datos = self.datos.dropna(subset=['Review Text', 'Class Name'])\n","        self.longitud_max = longitud_max\n","\n","        # Crear diccionario de tokens\n","        self.diccionario = DiccionarioTokens(min_frecuencia=UMBRAL_FRECUENCIA)\n","\n","        # Preparar textos combinados con separador diferente\n","        textos_completos = []\n","        for _, fila in self.datos.iterrows():\n","            categoria = str(fila['Class Name']).lower().strip()\n","            reseÃ±a = str(fila['Review Text']).lower().strip()\n","            texto_combinado = f\"{categoria} >>> {reseÃ±a}\"\n","            textos_completos.append(texto_combinado)\n","\n","        self.diccionario.construir_diccionario(textos_completos)\n","        print(f\"ğŸ“– TamaÃ±o del vocabulario: {len(self.diccionario)}\")\n","\n","    def __len__(self):\n","        return len(self.datos)\n","\n","    def __getitem__(self, indice):\n","        fila = self.datos.iloc[indice]\n","        categoria = str(fila['Class Name']).lower().strip()\n","        reseÃ±a = str(fila['Review Text']).strip()\n","\n","        # Combinar con el nuevo separador\n","        texto_completo = f\"{categoria} >>> {reseÃ±a}\"\n","\n","        # Convertir a Ã­ndices con tokens especiales\n","        indices = [self.diccionario.token_a_indice[\"[INICIO]\"]]\n","        indices.extend(self.diccionario.convertir_a_indices(texto_completo))\n","        indices.append(self.diccionario.token_a_indice[\"[FIN]\"])\n","\n","        # Aplicar padding\n","        tensor_padding = torch.zeros(self.longitud_max, dtype=torch.long)\n","        longitud_secuencia = min(len(indices), self.longitud_max)\n","        tensor_padding[:longitud_secuencia] = torch.tensor(indices[:longitud_secuencia])\n","\n","        # Preparar entrada y salida (shift by 1)\n","        entrada = tensor_padding[:-1]\n","        salida = tensor_padding[1:]\n","\n","        return entrada, salida"]},{"cell_type":"markdown","source":["# clase CodificacionPosicional:\n","Esta clase implementa la codificaciÃ³n posicional, una tÃ©cnica esencial en los modelos Transformer para que el modelo sepa el orden de las palabras en una secuencia. Genera una matriz con valores basados en funciones seno y coseno, que se suma a los embeddings de las palabras. AsÃ­, cada posiciÃ³n en la secuencia tiene una representaciÃ³n Ãºnica. AdemÃ¡s, aplica dropout para ayudar a evitar el sobreajuste.\n","\n","\n","*   __init__:\n","Inicializa la clase, crea la matriz de codificaciÃ³n posicional usando funciones seno y coseno para cada posiciÃ³n y dimensiÃ³n, y la guarda como un buffer (no se entrena).\n","\n","* **forward:**\n","Suma la codificaciÃ³n posicional a los embeddings de entrada y aplica dropout. AsÃ­, cada token tiene informaciÃ³n sobre su posiciÃ³n en la secuencia.\n","\n"],"metadata":{"id":"GkqvkD-TKI0D"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WFa7m-yzkP0N"},"outputs":[],"source":["class CodificacionPosicional(nn.Module):\n","    def __init__(self, dimension_embed, longitud_max=LONGITUD_MAXIMA, base=10000):\n","        super().__init__()\n","        self.dimension_embed = dimension_embed\n","        self.dropout = nn.Dropout(DROPOUT)\n","\n","        # Crear matriz de codificaciÃ³n posicional\n","        matriz_pe = torch.zeros(longitud_max, dimension_embed)\n","        posiciones = torch.arange(0, longitud_max).unsqueeze(1).float()\n","\n","        # Calcular divisores para frecuencias\n","        indices_pares = torch.arange(0, dimension_embed, 2).float()\n","        divisor = torch.pow(base, indices_pares / dimension_embed)\n","\n","        # Aplicar funciones seno y coseno\n","        matriz_pe[:, 0::2] = torch.sin(posiciones / divisor)\n","        matriz_pe[:, 1::2] = torch.cos(posiciones / divisor)\n","\n","        # Registrar como buffer (no se entrena)\n","        self.register_buffer('codificacion_pos', matriz_pe.unsqueeze(0))\n","\n","    def forward(self, embeddings):\n","        # Agregar codificaciÃ³n posicional y aplicar dropout\n","        longitud_seq = embeddings.size(1)\n","        salida = embeddings + self.codificacion_pos[:, :longitud_seq, :]\n","        return self.dropout(salida)"]},{"cell_type":"markdown","source":["# clase ModeloGeneradorTexto:\n","Esta clase define el modelo generador de texto basado en la arquitectura Transformer. Incluye una capa de embeddings para convertir los tokens en vectores, una codificaciÃ³n posicional para indicar el orden de los tokens, y un decodificador Transformer compuesto por varias capas de atenciÃ³n y feedforward. El modelo utiliza mÃ¡scaras causales para asegurar que cada posiciÃ³n solo pueda \"ver\" los tokens anteriores, lo que es esencial para la generaciÃ³n de texto. Finalmente, normaliza la salida y la proyecta al tamaÃ±o del vocabulario para predecir el siguiente token."],"metadata":{"id":"TrrIgD07Qjcn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xuDkV_NlkRHH"},"outputs":[],"source":["class ModeloGeneradorTexto(nn.Module):\n","    def __init__(self, tamaÃ±o_vocabulario, dim_modelo, num_cabezas, num_capas, dropout=DROPOUT):\n","        super().__init__()\n","\n","        # Capas de embedding\n","        self.capa_embedding = nn.Embedding(tamaÃ±o_vocabulario, dim_modelo)\n","        self.escala_embedding = math.sqrt(dim_modelo)\n","        self.codificador_posicion = CodificacionPosicional(dim_modelo)\n","\n","        # ConfiguraciÃ³n del decodificador transformer\n","        self.dropout_entrada = nn.Dropout(dropout)\n","        configuracion_capa = nn.TransformerDecoderLayer(\n","            d_model=dim_modelo,\n","            nhead=num_cabezas,\n","            dim_feedforward=dim_modelo * 4,\n","            dropout=dropout,\n","            activation='gelu',\n","            batch_first=True\n","        )\n","        self.decodificador = nn.TransformerDecoder(configuracion_capa, num_layers=num_capas)\n","\n","        # Capa de salida\n","        self.normalizacion_final = nn.LayerNorm(dim_modelo)\n","        self.proyeccion_salida = nn.Linear(dim_modelo, tamaÃ±o_vocabulario)\n","\n","        # InicializaciÃ³n de pesos\n","        self._inicializar_pesos()\n","\n","    def _inicializar_pesos(self):\n","        # InicializaciÃ³n Xavier para mejor convergencia\n","        for p in self.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p)\n","\n","    def crear_mascara_causal(self, tamaÃ±o):\n","        # Crear mÃ¡scara triangular superior para atenciÃ³n causal\n","        mascara = torch.triu(torch.ones(tamaÃ±o, tamaÃ±o), diagonal=1)\n","        return mascara.bool().to(self.capa_embedding.weight.device)\n","\n","    def forward(self, tokens_entrada, mascara_padding=None):\n","        tamaÃ±o_secuencia = tokens_entrada.size(1)\n","\n","        # Embeddings con escalamiento\n","        embeddings = self.capa_embedding(tokens_entrada) * self.escala_embedding\n","        embeddings_con_pos = self.codificador_posicion(embeddings)\n","        embeddings_con_pos = self.dropout_entrada(embeddings_con_pos)\n","\n","        # Crear mÃ¡scara causal\n","        mascara_atencion = self.crear_mascara_causal(tamaÃ±o_secuencia)\n","\n","        # Pasar por el decodificador\n","        salida_decodificador = self.decodificador(\n","            tgt=embeddings_con_pos,\n","            memory=embeddings_con_pos,\n","            tgt_mask=mascara_atencion,\n","            memory_mask=mascara_atencion,\n","            tgt_key_padding_mask=mascara_padding,\n","            memory_key_padding_mask=mascara_padding\n","        )\n","\n","        # NormalizaciÃ³n y proyecciÃ³n final\n","        salida_normalizada = self.normalizacion_final(salida_decodificador)\n","        logits = self.proyeccion_salida(salida_normalizada)\n","\n","        return logits"]},{"cell_type":"markdown","source":["\n","\n","* __init__:\n","Inicializa todas las capas del modelo: embeddings, codificaciÃ³n posicional, decodificador Transformer, normalizaciÃ³n y capa de salida. TambiÃ©n prepara la inicializaciÃ³n de los pesos.\n","\n","* **_inicializar_pesos:**\n","Aplica la inicializaciÃ³n Xavier a los pesos del modelo para mejorar la convergencia durante el entrenamiento.\n","\n","* **crear_mascara_causal:**\n","Genera una mÃ¡scara triangular que impide que el modelo vea tokens futuros durante la generaciÃ³n de texto (atenciÃ³n causal).\n","\n","* **forward:**\n","Define el paso hacia adelante del modelo: convierte los tokens en embeddings, suma la codificaciÃ³n posicional, aplica dropout, crea la mÃ¡scara causal, pasa los datos por el decodificador y finalmente normaliza y proyecta la salida para obtener las predicciones.\n","\n"],"metadata":{"id":"T54rK_i-Q9nD"}},{"cell_type":"markdown","source":["# FunciÃ³n entrenar_epoca:\n","Esta funciÃ³n realiza una Ã©poca completa de entrenamiento del modelo. Recorre los lotes de datos, mueve los tensores al dispositivo adecuado (CPU o GPU), crea la mÃ¡scara de padding, realiza la predicciÃ³n del modelo y calcula la pÃ©rdida. AdemÃ¡s, implementa la acumulaciÃ³n de gradientes para optimizar el uso de memoria, aplica \"gradient clipping\" para evitar inestabilidades y actualiza los pesos del modelo con el optimizador. Al final, devuelve la pÃ©rdida promedio de la Ã©poca."],"metadata":{"id":"_9atrijKRc1J"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vLtb-8c_kUF-"},"outputs":[],"source":["def entrenar_epoca(modelo, cargador_datos, optimizador, funcion_perdida, indice_pad, acumulacion_grad=1):\n","    modelo.train()\n","    perdida_acumulada = 0.0\n","    num_actualizaciones = 0\n","\n","    for batch_idx, (entrada, objetivo) in enumerate(cargador_datos):\n","        # Mover datos a dispositivo\n","        entrada = entrada.to(DISPOSITIVO)\n","        objetivo = objetivo.to(DISPOSITIVO)\n","\n","        # Crear mÃ¡scara de padding\n","        mascara_padding = (entrada == indice_pad)\n","\n","        # Forward pass\n","        predicciones = modelo(entrada, mascara_padding)\n","\n","        # Calcular pÃ©rdida\n","        perdida = funcion_perdida(\n","            predicciones.reshape(-1, predicciones.size(-1)),\n","            objetivo.reshape(-1)\n","        )\n","\n","        # Normalizar pÃ©rdida para acumulaciÃ³n de gradientes\n","        perdida = perdida / acumulacion_grad\n","        perdida.backward()\n","\n","        # Actualizar pesos cada N pasos\n","        if (batch_idx + 1) % acumulacion_grad == 0:\n","            # Gradient clipping\n","            torch.nn.utils.clip_grad_norm_(modelo.parameters(), FACTOR_GRAD_CLIP)\n","\n","            # Paso del optimizador\n","            optimizador.step()\n","            optimizador.zero_grad()\n","            num_actualizaciones += 1\n","\n","        perdida_acumulada += perdida.item() * acumulacion_grad\n","\n","    return perdida_acumulada / len(cargador_datos)"]},{"cell_type":"markdown","source":["# FunciÃ³n generar_texto_reseÃ±a:\n","Esta funciÃ³n genera automÃ¡ticamente una reseÃ±a de producto usando el modelo entrenado. Comienza con el tipo de producto y un separador especial, y va prediciendo palabra por palabra hasta alcanzar la longitud mÃ¡xima o encontrar el token de fin. Utiliza tÃ©cnicas de muestreo probabilÃ­stico (top-k y temperatura) para hacer la generaciÃ³n mÃ¡s variada y natural. Finalmente, decodifica los Ã­ndices generados a texto, elimina los tokens especiales y devuelve solo la reseÃ±a generada."],"metadata":{"id":"uxgo_FgcSmLI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-kKcwvfPkYfK"},"outputs":[],"source":["def generar_texto_reseÃ±a(modelo, tipo_producto, diccionario, longitud_max=50, temperatura=1.0, top_k=50):\n","    modelo.eval()\n","\n","    # Preparar tokens iniciales\n","    texto_inicial = f\"{tipo_producto.lower()} >>>\"\n","    indices_tokens = [diccionario.token_a_indice[\"[INICIO]\"]]\n","    indices_tokens.extend(diccionario.convertir_a_indices(texto_inicial))\n","\n","    with torch.no_grad():\n","        for _ in range(longitud_max):\n","            # Preparar entrada\n","            tensor_entrada = torch.tensor(indices_tokens, dtype=torch.long).unsqueeze(0).to(DISPOSITIVO)\n","\n","            # Obtener predicciones\n","            salida = modelo(tensor_entrada)\n","            logits_siguiente = salida[0, -1, :] / temperatura\n","\n","            # Aplicar top-k sampling\n","            if top_k > 0:\n","                valores, indices = torch.topk(logits_siguiente, top_k)\n","                logits_siguiente[logits_siguiente < valores[-1]] = -float('Inf')\n","\n","            # Muestreo probabilÃ­stico\n","            probabilidades = F.softmax(logits_siguiente, dim=-1)\n","            token_predicho = torch.multinomial(probabilidades, 1).item()\n","\n","            indices_tokens.append(token_predicho)\n","\n","            # Verificar token de fin\n","            if token_predicho == diccionario.token_a_indice[\"[FIN]\"]:\n","                break\n","\n","    # Decodificar tokens a texto\n","    tokens_finales = indices_tokens[1:]  # Omitir [INICIO]\n","    if diccionario.token_a_indice[\"[FIN]\"] in tokens_finales:\n","        idx_fin = tokens_finales.index(diccionario.token_a_indice[\"[FIN]\"])\n","        tokens_finales = tokens_finales[:idx_fin]\n","\n","    # Convertir a palabras\n","    palabras = []\n","    for idx in tokens_finales:\n","        if idx in diccionario.indice_a_token:\n","            token = diccionario.indice_a_token[idx]\n","            if token not in [\"[INICIO]\", \"[FIN]\", \"[PAD]\"]:\n","                palabras.append(token)\n","\n","    texto_generado = ' '.join(palabras)\n","\n","    # Limpiar y retornar solo la reseÃ±a\n","    if \">>>\" in texto_generado:\n","        partes = texto_generado.split(\">>>\", 1)\n","        return partes[1].strip() if len(partes) > 1 else texto_generado\n","    return texto_generado"]},{"cell_type":"markdown","source":["# FunciÃ³n evaluar_calidad_generacion:\n","Esta funciÃ³n evalÃºa la calidad de los textos generados por el modelo utilizando mÃ©tricas automÃ¡ticas. Para varias muestras del conjunto de datos, genera un texto, lo compara con el texto real y calcula las mÃ©tricas BLEU y ROUGE (ROUGE-1, ROUGE-2 y ROUGE-L), que miden la similitud entre el texto generado y el de referencia. Muestra los resultados de cada muestra y, al final, presenta un resumen con los promedios y desviaciones estÃ¡ndar de las mÃ©tricas obtenidas."],"metadata":{"id":"UxB1U9-CSRcw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3rET_HJ4kZnK"},"outputs":[],"source":["def evaluar_calidad_generacion(modelo, conjunto_datos, diccionario, num_muestras=15, temperatura=0.8):\n","    # Listas para almacenar mÃ©tricas\n","    metricas_bleu = []\n","    metricas_rouge1 = []\n","    metricas_rouge2 = []\n","    metricas_rougeL = []\n","\n","    print(\"ğŸ” Evaluando calidad del modelo generativo...\\n\")\n","\n","    for idx in range(min(num_muestras, len(conjunto_datos))):\n","        # Obtener datos de referencia\n","        tipo_articulo = conjunto_datos.datos.iloc[idx]['Class Name']\n","        texto_referencia = conjunto_datos.datos.iloc[idx]['Review Text']\n","\n","        # Generar texto\n","        texto_generado = generar_texto_reseÃ±a(\n","            modelo, tipo_articulo, diccionario,\n","            longitud_max=60, temperatura=temperatura\n","        )\n","\n","        # Tokenizar para BLEU\n","        tokens_referencia = word_tokenize(texto_referencia.lower())\n","        tokens_generados = word_tokenize(texto_generado.lower())\n","\n","        # Calcular BLEU\n","        puntuacion_bleu = sentence_bleu(\n","            [tokens_referencia],\n","            tokens_generados,\n","            smoothing_function=smooth_function\n","        )\n","\n","        # Calcular ROUGE\n","        puntuaciones_rouge = evaluador_rouge.score(texto_referencia, texto_generado)\n","\n","        # Almacenar mÃ©tricas\n","        metricas_bleu.append(puntuacion_bleu)\n","        metricas_rouge1.append(puntuaciones_rouge['rouge1'].fmeasure)\n","        metricas_rouge2.append(puntuaciones_rouge['rouge2'].fmeasure)\n","        metricas_rougeL.append(puntuaciones_rouge['rougeL'].fmeasure)\n","\n","        # Mostrar resultados\n","        print(f\"ğŸ“ Muestra {idx+1}/{num_muestras}\")\n","        print(f\"   CategorÃ­a: {tipo_articulo}\")\n","        print(f\"   BLEU: {puntuacion_bleu:.3f} | R-1: {puntuaciones_rouge['rouge1'].fmeasure:.3f} | R-2: {puntuaciones_rouge['rouge2'].fmeasure:.3f} | R-L: {puntuaciones_rouge['rougeL'].fmeasure:.3f}\")\n","        print(f\"   Referencia: {texto_referencia[:100]}...\")\n","        print(f\"   Generado: {texto_generado[:100]}...\")\n","        print(\"-\" * 80)\n","\n","    # EstadÃ­sticas finales\n","    print(\"\\nğŸ“Š RESUMEN DE MÃ‰TRICAS\")\n","    print(\"=\" * 50)\n","    print(f\"BLEU promedio:    {np.mean(metricas_bleu):.4f} (Â±{np.std(metricas_bleu):.4f})\")\n","    print(f\"ROUGE-1 promedio: {np.mean(metricas_rouge1):.4f} (Â±{np.std(metricas_rouge1):.4f})\")\n","    print(f\"ROUGE-2 promedio: {np.mean(metricas_rouge2):.4f} (Â±{np.std(metricas_rouge2):.4f})\")\n","    print(f\"ROUGE-L promedio: {np.mean(metricas_rougeL):.4f} (Â±{np.std(metricas_rougeL):.4f})\")\n","\n","    return {\n","        'bleu': metricas_bleu,\n","        'rouge1': metricas_rouge1,\n","        'rouge2': metricas_rouge2,\n","        'rougeL': metricas_rougeL\n","    }"]},{"cell_type":"markdown","source":["# Entrenamiento del Modelo\n","\n","En este bloque se realiza toda la preparaciÃ³n y ejecuciÃ³n del proceso de entrenamiento del modelo generador de texto. Se cargan los datos desde un archivo CSV, se construye el conjunto de datos y el dataloader, y se configura el vocabulario. Luego, se inicializa el modelo Transformer, el optimizador, el scheduler para ajustar la tasa de aprendizaje y la funciÃ³n de pÃ©rdida con suavizado de etiquetas.\n","\n","A continuaciÃ³n, se ejecuta el bucle de entrenamiento durante varias Ã©pocas, mostrando el progreso, la pÃ©rdida y el tiempo de cada Ã©poca. El modelo se guarda automÃ¡ticamente cuando mejora la pÃ©rdida, y cada cierto nÃºmero de Ã©pocas se generan ejemplos de texto para monitorear la calidad del modelo."],"metadata":{"id":"SyoAs9pPSzxy"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mDNXHEh2kbC8","executionInfo":{"status":"ok","timestamp":1752604421466,"user_tz":240,"elapsed":4629221,"user":{"displayName":"Matias soto uribe","userId":"03140738076259130257"}},"outputId":"4419ec03-a88b-4a18-ad4c-cda78756b37d"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ“ Cargando conjunto de datos...\n","âœ“ Total de registros encontrados: 23486\n","ğŸ“– TamaÃ±o del vocabulario: 6709\n","ğŸ“š TamaÃ±o del vocabulario construido: 6709\n","ğŸ”¢ Total de lotes por Ã©poca: 354\n","\n","ğŸ—ï¸ Construyendo arquitectura del modelo...\n","ğŸ“Š Total de parÃ¡metros: 19,489,845\n","ğŸ“Š ParÃ¡metros entrenables: 19,489,845\n","\n","ğŸš€ INICIANDO PROCESO DE ENTRENAMIENTO\n","============================================================\n","ğŸ“ˆ Ã‰poca 1/45 | PÃ©rdida: 5.2344 | LR: 0.000200 | Tiempo: 95.1s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 2/45 | PÃ©rdida: 4.4949 | LR: 0.000199 | Tiempo: 98.6s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 3/45 | PÃ©rdida: 4.2863 | LR: 0.000198 | Tiempo: 101.0s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 4/45 | PÃ©rdida: 4.1594 | LR: 0.000197 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 5/45 | PÃ©rdida: 4.0694 | LR: 0.000195 | Tiempo: 101.8s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 6/45 | PÃ©rdida: 3.9973 | LR: 0.000192 | Tiempo: 101.7s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 7/45 | PÃ©rdida: 3.9362 | LR: 0.000189 | Tiempo: 101.9s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 8/45 | PÃ©rdida: 3.8829 | LR: 0.000186 | Tiempo: 101.8s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 9/45 | PÃ©rdida: 3.8346 | LR: 0.000183 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 10/45 | PÃ©rdida: 3.7912 | LR: 0.000179 | Tiempo: 101.6s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","\n","ğŸ¯ Generando muestras de ejemplo:\n","   â€¢ tops: i really liked this top when i tried it on . i ' m 5 ' 4 \", 145 lbs . the small ...\n","   â€¢ jeans: these jeans are perfect . they are flattering and fit well ....\n","   â€¢ shoes: i love the look of this piece . it is so cute and easy to wear . i am 5 ' 2 \" an...\n","ğŸ“ˆ Ã‰poca 11/45 | PÃ©rdida: 3.7505 | LR: 0.000175 | Tiempo: 101.8s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 12/45 | PÃ©rdida: 3.7118 | LR: 0.000170 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 13/45 | PÃ©rdida: 3.6757 | LR: 0.000165 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 14/45 | PÃ©rdida: 3.6407 | LR: 0.000160 | Tiempo: 101.6s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 15/45 | PÃ©rdida: 3.6075 | LR: 0.000155 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 16/45 | PÃ©rdida: 3.5774 | LR: 0.000149 | Tiempo: 101.6s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 17/45 | PÃ©rdida: 3.5467 | LR: 0.000144 | Tiempo: 101.6s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 18/45 | PÃ©rdida: 3.5164 | LR: 0.000138 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 19/45 | PÃ©rdida: 3.4881 | LR: 0.000132 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 20/45 | PÃ©rdida: 3.4614 | LR: 0.000126 | Tiempo: 101.8s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","\n","ğŸ¯ Generando muestras de ejemplo:\n","   â€¢ tops: i love this vest . it ' s soft and can be dressed up or down . it ' s very flatt...\n","   â€¢ jeans: i have a few pairs of these jeans from last year and love them . they fit my fir...\n","   â€¢ shoes: i ' m so glad i bought this . i absolutely adore this outfit ! it has the right ...\n","ğŸ“ˆ Ã‰poca 21/45 | PÃ©rdida: 3.4358 | LR: 0.000119 | Tiempo: 101.7s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 22/45 | PÃ©rdida: 3.4103 | LR: 0.000113 | Tiempo: 101.7s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 23/45 | PÃ©rdida: 3.3871 | LR: 0.000107 | Tiempo: 101.8s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 24/45 | PÃ©rdida: 3.3639 | LR: 0.000101 | Tiempo: 101.8s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 25/45 | PÃ©rdida: 3.3419 | LR: 0.000094 | Tiempo: 101.7s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 26/45 | PÃ©rdida: 3.3215 | LR: 0.000088 | Tiempo: 101.9s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 27/45 | PÃ©rdida: 3.3029 | LR: 0.000082 | Tiempo: 102.0s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 28/45 | PÃ©rdida: 3.2839 | LR: 0.000076 | Tiempo: 102.0s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 29/45 | PÃ©rdida: 3.2666 | LR: 0.000071 | Tiempo: 102.0s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 30/45 | PÃ©rdida: 3.2505 | LR: 0.000065 | Tiempo: 102.1s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","\n","ğŸ¯ Generando muestras de ejemplo:\n","   â€¢ tops: this is a really cute piece . i love the length and the color . i ' m 5 ' 1 \" an...\n","   â€¢ jeans: i love these jeans ! i ordered them in size 26 and they fit perfectly ! they are...\n","   â€¢ shoes: i was so excited to get this in the mail . unfortunately the fit was so off . it...\n","ğŸ“ˆ Ã‰poca 31/45 | PÃ©rdida: 3.2348 | LR: 0.000060 | Tiempo: 101.8s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 32/45 | PÃ©rdida: 3.2202 | LR: 0.000055 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 33/45 | PÃ©rdida: 3.2080 | LR: 0.000050 | Tiempo: 101.6s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 34/45 | PÃ©rdida: 3.1959 | LR: 0.000045 | Tiempo: 101.7s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 35/45 | PÃ©rdida: 3.1840 | LR: 0.000041 | Tiempo: 101.7s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 36/45 | PÃ©rdida: 3.1738 | LR: 0.000037 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 37/45 | PÃ©rdida: 3.1642 | LR: 0.000034 | Tiempo: 101.6s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 38/45 | PÃ©rdida: 3.1556 | LR: 0.000031 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 39/45 | PÃ©rdida: 3.1472 | LR: 0.000028 | Tiempo: 101.7s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 40/45 | PÃ©rdida: 3.1409 | LR: 0.000025 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","\n","ğŸ¯ Generando muestras de ejemplo:\n","   â€¢ tops: i love this top . i was able to arrive in an xs , and it was too large on me , a...\n","   â€¢ jeans: i tried on the regular size in the store in the regular size 27 ( 5 ' 3 \", 110lb...\n","   â€¢ shoes: i loved this online and ordered it in both colors . i am usually a small but ord...\n","ğŸ“ˆ Ã‰poca 41/45 | PÃ©rdida: 3.1347 | LR: 0.000023 | Tiempo: 101.6s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 42/45 | PÃ©rdida: 3.1293 | LR: 0.000022 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 43/45 | PÃ©rdida: 3.1227 | LR: 0.000021 | Tiempo: 101.6s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 44/45 | PÃ©rdida: 3.1191 | LR: 0.000020 | Tiempo: 101.6s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","ğŸ“ˆ Ã‰poca 45/45 | PÃ©rdida: 3.1146 | LR: 0.000020 | Tiempo: 101.5s\n","   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\n","\n","âœ… ENTRENAMIENTO COMPLETADO\n","ğŸ† Mejor pÃ©rdida alcanzada: 3.1146\n"]}],"source":["# === CONFIGURACIÃ“N DEL SISTEMA DE ENTRENAMIENTO ===\n","\n","# Rutas de archivos\n","RUTA_DATOS = \"/content/drive/MyDrive/ET_deep_learning/Reviews.csv\"\n","RUTA_GUARDAR_MODELO = \"/content/drive/MyDrive/ET_deep_learning/modelo_generativo_v2.pth\"\n","\n","# Verificar disponibilidad de datos\n","print(\"ğŸ“ Cargando conjunto de datos...\")\n","datos_brutos = pd.read_csv(RUTA_DATOS)\n","print(f\"âœ“ Total de registros encontrados: {len(datos_brutos)}\")\n","\n","# Crear dataset y dataloader\n","conjunto_entrenamiento = ConjuntoDatosReseÃ±as(RUTA_DATOS)\n","cargador_entrenamiento = DataLoader(\n","    conjunto_entrenamiento,\n","    batch_size=TAMAÃ‘O_LOTE,\n","    shuffle=True,\n","    num_workers=2 if DISPOSITIVO.type == 'cuda' else 0,\n","    pin_memory=True if DISPOSITIVO.type == 'cuda' else False\n",")\n","\n","# ConfiguraciÃ³n del vocabulario\n","diccionario_vocabulario = conjunto_entrenamiento.diccionario\n","indice_padding = diccionario_vocabulario.token_a_indice[\"[PAD]\"]\n","tamaÃ±o_vocabulario = len(diccionario_vocabulario)\n","\n","print(f\"ğŸ“š TamaÃ±o del vocabulario construido: {tamaÃ±o_vocabulario}\")\n","print(f\"ğŸ”¢ Total de lotes por Ã©poca: {len(cargador_entrenamiento)}\")\n","\n","# === INICIALIZACIÃ“N DEL MODELO ===\n","print(\"\\nğŸ—ï¸ Construyendo arquitectura del modelo...\")\n","modelo_generativo = ModeloGeneradorTexto(\n","    tamaÃ±o_vocabulario=tamaÃ±o_vocabulario,\n","    dim_modelo=DIM_EMBEDDING,\n","    num_cabezas=CABEZAS_ATENCION,\n","    num_capas=CAPAS_TRANSFORMER,\n","    dropout=DROPOUT\n",").to(DISPOSITIVO)\n","\n","# Contar parÃ¡metros\n","total_parametros = sum(p.numel() for p in modelo_generativo.parameters())\n","parametros_entrenables = sum(p.numel() for p in modelo_generativo.parameters() if p.requires_grad)\n","print(f\"ğŸ“Š Total de parÃ¡metros: {total_parametros:,}\")\n","print(f\"ğŸ“Š ParÃ¡metros entrenables: {parametros_entrenables:,}\")\n","\n","# ConfiguraciÃ³n del optimizador con scheduler\n","optimizador = torch.optim.AdamW(\n","    modelo_generativo.parameters(),\n","    lr=TASA_APRENDIZAJE,\n","    betas=(0.9, 0.98),\n","    eps=1e-9,\n","    weight_decay=0.01\n",")\n","\n","# Learning rate scheduler\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n","    optimizador,\n","    T_max=NUM_EPOCAS,\n","    eta_min=TASA_APRENDIZAJE * 0.1\n",")\n","\n","# FunciÃ³n de pÃ©rdida con label smoothing\n","criterio_perdida = nn.CrossEntropyLoss(\n","    ignore_index=indice_padding,\n","    label_smoothing=0.1\n",")\n","\n","# === BUCLE DE ENTRENAMIENTO ===\n","print(\"\\nğŸš€ INICIANDO PROCESO DE ENTRENAMIENTO\")\n","print(\"=\" * 60)\n","\n","historial_perdidas = []\n","mejor_perdida = float('inf')\n","\n","for epoca in range(1, NUM_EPOCAS + 1):\n","    tiempo_inicio = torch.cuda.Event(enable_timing=True) if DISPOSITIVO.type == 'cuda' else None\n","    tiempo_fin = torch.cuda.Event(enable_timing=True) if DISPOSITIVO.type == 'cuda' else None\n","\n","    if tiempo_inicio:\n","        tiempo_inicio.record()\n","\n","    # Entrenar una Ã©poca\n","    perdida_epoca = entrenar_epoca(\n","        modelo_generativo,\n","        cargador_entrenamiento,\n","        optimizador,\n","        criterio_perdida,\n","        indice_padding\n","    )\n","\n","    historial_perdidas.append(perdida_epoca)\n","\n","    # Actualizar learning rate\n","    scheduler.step()\n","    lr_actual = scheduler.get_last_lr()[0]\n","\n","    if tiempo_fin:\n","        tiempo_fin.record()\n","        torch.cuda.synchronize()\n","        tiempo_epoca = tiempo_inicio.elapsed_time(tiempo_fin) / 1000.0\n","    else:\n","        tiempo_epoca = 0\n","\n","    # Mostrar progreso\n","    print(f\"ğŸ“ˆ Ã‰poca {epoca}/{NUM_EPOCAS} | PÃ©rdida: {perdida_epoca:.4f} | LR: {lr_actual:.6f} | Tiempo: {tiempo_epoca:.1f}s\")\n","\n","    # Guardar mejor modelo\n","    if perdida_epoca < mejor_perdida:\n","        mejor_perdida = perdida_epoca\n","        print(f\"   âœ¨ Nueva mejor pÃ©rdida! Guardando modelo...\")\n","        torch.save({\n","            'epoch': epoca,\n","            'model_state_dict': modelo_generativo.state_dict(),\n","            'optimizer_state_dict': optimizador.state_dict(),\n","            'loss': perdida_epoca,\n","            'vocab_size': tamaÃ±o_vocabulario,\n","            'config': {\n","                'dim_embedding': DIM_EMBEDDING,\n","                'num_heads': CABEZAS_ATENCION,\n","                'num_layers': CAPAS_TRANSFORMER,\n","                'dropout': DROPOUT\n","            }\n","        }, RUTA_GUARDAR_MODELO)\n","\n","    # Generar muestras cada 10 Ã©pocas\n","    if epoca % 10 == 0:\n","        print(\"\\nğŸ¯ Generando muestras de ejemplo:\")\n","        for categoria in [\"tops\", \"jeans\", \"shoes\"]:\n","            texto_muestra = generar_texto_reseÃ±a(modelo_generativo, categoria, diccionario_vocabulario, temperatura=0.7)\n","            print(f\"   â€¢ {categoria}: {texto_muestra[:80]}...\")\n","\n","print(\"\\nâœ… ENTRENAMIENTO COMPLETADO\")\n","print(f\"ğŸ† Mejor pÃ©rdida alcanzada: {mejor_perdida:.4f}\")"]},{"cell_type":"markdown","source":["\n","Cantidad de datos:\n","El modelo fue entrenado con 23,486 registros y un vocabulario de 6,709 tokens. Esto es un tamaÃ±o considerable, lo que ayuda a que el modelo generalice mejor.\n","\n","ParÃ¡metros:\n","El modelo tiene 19,489,845 parÃ¡metros entrenables, lo que indica una arquitectura robusta y capaz de aprender patrones complejos.\n","\n","PÃ©rdida (Loss):\n","La pÃ©rdida inicial en la primera Ã©poca fue de 5.2344.\n","La pÃ©rdida fue disminuyendo de manera constante en cada Ã©poca, lo que es una seÃ±al de que el modelo estÃ¡ aprendiendo correctamente.\n","La mejor pÃ©rdida alcanzada fue de 3.1146 en la Ãºltima Ã©poca (45/45).\n","Cada vez que la pÃ©rdida mejorÃ³, el modelo fue guardado automÃ¡ticamente."],"metadata":{"id":"IkobKPldfBz_"}},{"cell_type":"markdown","source":["# Fase de evaluaciÃ³n y generaciÃ³n:\n","En esta secciÃ³n se evalÃºa el modelo entrenado y se generan ejemplos de reseÃ±as. Primero, se generan textos para diferentes categorÃ­as y temperaturas, mostrando cÃ³mo varÃ­a la creatividad del modelo segÃºn el parÃ¡metro de temperatura. Luego, se realiza una evaluaciÃ³n automÃ¡tica del modelo usando mÃ©tricas como BLEU y ROUGE sobre varias muestras, y se presentan estadÃ­sticas detalladas (percentiles, mÃ­nimo y mÃ¡ximo) de los resultados obtenidos. Finalmente, se muestra un resumen con informaciÃ³n relevante sobre el modelo, el vocabulario y el dispositivo utilizado."],"metadata":{"id":"tmPiyzWOTTew"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ts51gJFkc1M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752604427161,"user_tz":240,"elapsed":5692,"user":{"displayName":"Matias soto uribe","userId":"03140738076259130257"}},"outputId":"38b76f87-ef11-432c-d90b-55e615d67e6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ğŸ¨ GENERACIÃ“N DE EJEMPLOS DE RESEÃ‘AS\n","============================================================\n","\n","ğŸ“ Generando reseÃ±as con diferentes temperaturas:\n","\n","\n","ğŸŒ¡ï¸ Temperatura = 0.5\n","----------------------------------------\n","ğŸ“¦ BLOUSES:\n","   i just received this top in the mail and i love it . i am 5 ' 2 \", 120 lbs and 34b and i got the xs . i could probably have gone with an xxs , but i\n","\n","ğŸ“¦ DRESSES:\n","   this dress is beautiful and fits true to size . i am 5 ' 5 \" and about 120 lbs . i ordered a 4 petite and it fits perfectly . i can ' t wait to wear it !\n","\n","ğŸ“¦ PANTS:\n","   i love these pants , they are so comfortable , and stylish . i am 5 ' 10 \", and the length is perfect for me . they are the perfect length for me , they are not too long\n","\n","\n","ğŸŒ¡ï¸ Temperatura = 0.8\n","----------------------------------------\n","ğŸ“¦ BLOUSES:\n","   i love this top . i bought it in both the black and white colors . i thought it would be a great top to wear for work or play . i did size up because i have broad shoulders\n","\n","ğŸ“¦ DRESSES:\n","   the color and cut of this dress are gorgeous , but the fit was so tight . i would have kept it if it weren ' t the cut or the dress was correctly on me . maybe i '\n","\n","ğŸ“¦ PANTS:\n","   i love the cut and style of this jumpsuit . it is so flattering and can be worn on or off shoulder .\n","\n","\n","ğŸŒ¡ï¸ Temperatura = 1.0\n","----------------------------------------\n","ğŸ“¦ BLOUSES:\n","   this top is absolutely fabulous . i wore it for work and received tons of compliments !\n","\n","ğŸ“¦ DRESSES:\n","   so glad i saw this online -- i read the previous reviews of the dress and decided to get it . sadly , the dress is [DESCONOCIDO] of a [DESCONOCIDO] review so i purchased it before i ordered it .\n","\n","ğŸ“¦ PANTS:\n","   i bought the white jumpsuit as a gift for a friend . she loved it . it was a favorite . it is comfortable , easy and very flattering .\n","\n","\n","\n","ğŸ”¬ EVALUACIÃ“N DETALLADA DEL MODELO\n","============================================================\n","ğŸ” Evaluando calidad del modelo generativo...\n","\n","ğŸ“ Muestra 1/20\n","   CategorÃ­a: Intimates\n","   BLEU: 0.022 | R-1: 0.063 | R-2: 0.000 | R-L: 0.063\n","   Referencia: Absolutely wonderful - silky and sexy and comfortable...\n","   Generado: i knew this chemise would be a must - have been a summer staple in the past year . it can be a great...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 2/20\n","   CategorÃ­a: Dresses\n","   BLEU: 0.063 | R-1: 0.458 | R-2: 0.121 | R-L: 0.254\n","   Referencia: Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never...\n","   Generado: i just received this dress and i ' m very happy with it . i have taken such a to fit and look great ...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 3/20\n","   CategorÃ­a: Dresses\n","   BLEU: 0.023 | R-1: 0.274 | R-2: 0.028 | R-L: 0.164\n","   Referencia: I had such high hopes for this dress and really wanted it to work for me. i initially ordered the pe...\n","   Generado: i ordered this dress in the navy and love it . the fit is perfect - not too long , not too short or ...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 4/20\n","   CategorÃ­a: Pants\n","   BLEU: 0.036 | R-1: 0.189 | R-2: 0.028 | R-L: 0.135\n","   Referencia: I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothin...\n","   Generado: this jumpsuit is great ! great quality and construction ! the top is a bit wide but a little too sho...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 5/20\n","   CategorÃ­a: Blouses\n","   BLEU: 0.039 | R-1: 0.211 | R-2: 0.000 | R-L: 0.140\n","   Referencia: This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to we...\n","   Generado: love it ! i usually wear a small , but only had to get a medium in this top ! great fall / winter sh...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 6/20\n","   CategorÃ­a: Dresses\n","   BLEU: 0.036 | R-1: 0.336 | R-2: 0.027 | R-L: 0.188\n","   Referencia: I love tracy reese dresses, but this one is not for the very petite. i am just under 5 feet tall and...\n","   Generado: this dress is even better in person . i am 5 ' description and ordered the petite size . it hits at ...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 7/20\n","   CategorÃ­a: Knits\n","   BLEU: 0.009 | R-1: 0.167 | R-2: 0.031 | R-L: 0.106\n","   Referencia: I aded this in my basket at hte last mintue to see what it would look like in person. (store pick up...\n","   Generado: i was looking for a casual , yet cute top for the spring . runs large , and i normally wear a medium...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 8/20\n","   CategorÃ­a: Knits\n","   BLEU: 0.020 | R-1: 0.276 | R-2: 0.013 | R-L: 0.171\n","   Referencia: I ordered this in carbon for store pick up, and had a ton of stuff (as always) to try on and used th...\n","   Generado: i bought this shirt in the green color . i like that it ' s not too thin and it ' s not see through ...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 9/20\n","   CategorÃ­a: Dresses\n","   BLEU: 0.069 | R-1: 0.434 | R-2: 0.123 | R-L: 0.265\n","   Referencia: I love this dress. i usually get an xs but it runs a little snug in bust so i ordered up a size. ver...\n","   Generado: tried this on in the store . i ' m 5 ' 4 \", 130lbs , 34 / b . i usually wear a size s . i ordered an...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 10/20\n","   CategorÃ­a: Dresses\n","   BLEU: 0.067 | R-1: 0.429 | R-2: 0.113 | R-L: 0.270\n","   Referencia: I'm 5\"5' and 125 lbs. i ordered the s petite to make sure the length wasn't too long. i typically we...\n","   Generado: i love this dress so much ! i ' m 5 ' 0 \" and the petite length of the dress fits just right ! i lov...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 11/20\n","   CategorÃ­a: Dresses\n","   BLEU: 0.017 | R-1: 0.182 | R-2: 0.023 | R-L: 0.114\n","   Referencia: Dress runs small esp where the zipper area runs. i ordered the sp which typically fits me and it was...\n","   Generado: i love this dress ! it is so cute on ! i wore it to a wedding and then i received so many compliment...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 12/20\n","   CategorÃ­a: Dresses\n","   BLEU: 0.090 | R-1: 0.303 | R-2: 0.129 | R-L: 0.303\n","   Referencia: This dress is perfection! so pretty and flattering....\n","   Generado: this dress is so comfortable and versatile on . i love the detail in the back and the detail . i am ...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 13/20\n","   CategorÃ­a: Dresses\n","   BLEU: 0.027 | R-1: 0.252 | R-2: 0.054 | R-L: 0.146\n","   Referencia: More and more i find myself reliant on the reviews written by savvy shoppers before me and for the m...\n","   Generado: i tried this dress on for my sister ' s birthday and she loved it ! she actually returned it and the...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 14/20\n","   CategorÃ­a: Intimates\n","   BLEU: 0.034 | R-1: 0.279 | R-2: 0.033 | R-L: 0.213\n","   Referencia: Bought the black xs to go under the larkspur midi dress because they didn't bother lining the skirt ...\n","   Generado: i am a 32dd and the medium fits perfectly . the colors are beautiful and the material is very comfor...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 15/20\n","   CategorÃ­a: Dresses\n","   BLEU: 0.036 | R-1: 0.290 | R-2: 0.042 | R-L: 0.152\n","   Referencia: This is a nice choice for holiday gatherings. i like that the length grazes the knee so it is conser...\n","   Generado: this dress is very pretty and is true to size . i ' m 5 ' 11 \" and this falls to my ankles ... which...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 16/20\n","   CategorÃ­a: Pants\n","   BLEU: 0.034 | R-1: 0.282 | R-2: 0.041 | R-L: 0.134\n","   Referencia: I took these out of the package and wanted them to fit so badly, but i could tell before i put them ...\n","   Generado: this is a very comfortable romper that has a unique design to it and is well made . however , it is ...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 17/20\n","   CategorÃ­a: Pants\n","   BLEU: 0.020 | R-1: 0.218 | R-2: 0.020 | R-L: 0.139\n","   Referencia: Material and color is nice.  the leg opening is very large.  i am 5'1 (100#) and the length hits me ...\n","   Generado: these pants are so cute . i ' m 5 ' 8 \" and the regular length is perfect . they fit great , are fla...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 18/20\n","   CategorÃ­a: Blouses\n","   BLEU: 0.034 | R-1: 0.289 | R-2: 0.045 | R-L: 0.156\n","   Referencia: Took a chance on this blouse and so glad i did. i wasn't crazy about how the blouse is photographed ...\n","   Generado: i am so glad i purchased this top ! it is great with a pair of jeans or slacks for work . it will be...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 19/20\n","   CategorÃ­a: Outerwear\n","   BLEU: 0.098 | R-1: 0.289 | R-2: 0.049 | R-L: 0.169\n","   Referencia: A flattering, super cozy coat.  will work well for cold, dry days and will look good with jeans or a...\n","   Generado: i bought this coat in the store , size small . i am 5 ' 4 \" 125 and 130lbs , i bought the size small...\n","--------------------------------------------------------------------------------\n","ğŸ“ Muestra 20/20\n","   CategorÃ­a: Dresses\n","   BLEU: 0.070 | R-1: 0.421 | R-2: 0.089 | R-L: 0.246\n","   Referencia: I love the look and feel of this tulle dress. i was looking for something different, but not over th...\n","   Generado: i got this dress in the mail and was so thrilled with the fit and feel of the fabric . however , i p...\n","--------------------------------------------------------------------------------\n","\n","ğŸ“Š RESUMEN DE MÃ‰TRICAS\n","==================================================\n","BLEU promedio:    0.0421 (Â±0.0244)\n","ROUGE-1 promedio: 0.2820 (Â±0.0970)\n","ROUGE-2 promedio: 0.0505 (Â±0.0403)\n","ROUGE-L promedio: 0.1764 (Â±0.0612)\n","\n","\n","ğŸ“Š ANÃLISIS ESTADÃSTICO ADICIONAL\n","============================================================\n","\n","BLEU:\n","  - P25: 0.0230\n","  - P50 (mediana): 0.0350\n","  - P75: 0.0641\n","  - Min: 0.0092\n","  - Max: 0.0981\n","\n","ROUGE1:\n","  - P25: 0.2160\n","  - P50 (mediana): 0.2803\n","  - P75: 0.3112\n","  - Min: 0.0635\n","  - Max: 0.4576\n","\n","ROUGE2:\n","  - P25: 0.0262\n","  - P50 (mediana): 0.0371\n","  - P75: 0.0626\n","  - Min: 0.0000\n","  - Max: 0.1290\n","\n","ROUGEL:\n","  - P25: 0.1377\n","  - P50 (mediana): 0.1600\n","  - P75: 0.2212\n","  - Min: 0.0635\n","  - Max: 0.3030\n","\n","\n","âœ¨ PROCESO COMPLETADO EXITOSAMENTE âœ¨\n","ğŸ“ Modelo guardado en: /content/drive/MyDrive/ET_deep_learning/modelo_generativo_v2.pth\n","ğŸ“Š Vocabulario final: 6709 tokens\n","âš¡ Dispositivo utilizado: cuda\n","\n","ğŸ‰ Â¡Gracias por usar este sistema de generaciÃ³n de reseÃ±as!\n"]}],"source":["# === FASE DE EVALUACIÃ“N Y GENERACIÃ“N ===\n","\n","print(\"\\nğŸ¨ GENERACIÃ“N DE EJEMPLOS DE RESEÃ‘AS\")\n","print(\"=\" * 60)\n","\n","# Lista de categorÃ­as para probar\n","categorias_prueba = [\"blouses\", \"dresses\", \"pants\", \"sweaters\", \"jackets\"]\n","\n","print(\"\\nğŸ“ Generando reseÃ±as con diferentes temperaturas:\\n\")\n","\n","for temperatura in [0.5, 0.8, 1.0]:\n","    print(f\"\\nğŸŒ¡ï¸ Temperatura = {temperatura}\")\n","    print(\"-\" * 40)\n","\n","    for categoria in categorias_prueba[:3]:  # Solo las primeras 3 para demostraciÃ³n\n","        reseÃ±a_generada = generar_texto_reseÃ±a(\n","            modelo_generativo,\n","            categoria,\n","            diccionario_vocabulario,\n","            longitud_max=40,\n","            temperatura=temperatura,\n","            top_k=40\n","        )\n","        print(f\"ğŸ“¦ {categoria.upper()}:\")\n","        print(f\"   {reseÃ±a_generada}\\n\")\n","\n","# === EVALUACIÃ“N COMPLETA DEL MODELO ===\n","print(\"\\n\\nğŸ”¬ EVALUACIÃ“N DETALLADA DEL MODELO\")\n","print(\"=\" * 60)\n","\n","# Evaluar con mÃ©tricas automÃ¡ticas\n","resultados_metricas = evaluar_calidad_generacion(\n","    modelo_generativo,\n","    conjunto_entrenamiento,\n","    diccionario_vocabulario,\n","    num_muestras=20,\n","    temperatura=0.8\n",")\n","\n","# VisualizaciÃ³n adicional\n","print(\"\\n\\nğŸ“Š ANÃLISIS ESTADÃSTICO ADICIONAL\")\n","print(\"=\" * 60)\n","\n","# Calcular percentiles\n","for metrica, valores in resultados_metricas.items():\n","    p25 = np.percentile(valores, 25)\n","    p50 = np.percentile(valores, 50)\n","    p75 = np.percentile(valores, 75)\n","    print(f\"\\n{metrica.upper()}:\")\n","    print(f\"  - P25: {p25:.4f}\")\n","    print(f\"  - P50 (mediana): {p50:.4f}\")\n","    print(f\"  - P75: {p75:.4f}\")\n","    print(f\"  - Min: {min(valores):.4f}\")\n","    print(f\"  - Max: {max(valores):.4f}\")\n","\n","# Mensaje final\n","print(\"\\n\\nâœ¨ PROCESO COMPLETADO EXITOSAMENTE âœ¨\")\n","print(f\"ğŸ“ Modelo guardado en: {RUTA_GUARDAR_MODELO}\")\n","print(f\"ğŸ“Š Vocabulario final: {tamaÃ±o_vocabulario} tokens\")\n","print(f\"âš¡ Dispositivo utilizado: {DISPOSITIVO}\")\n","print(\"\\nğŸ‰ Â¡Gracias por usar este sistema de generaciÃ³n de reseÃ±as!\")"]},{"cell_type":"markdown","source":["**Â¿QuÃ© miden estas mÃ©tricas?**\n","\n","**BLEU:**\n","Mide la coincidencia de n-gramas (palabras o secuencias de palabras) entre el texto generado y el de referencia.\n","\n","**0:** Nada coincide, 1: Coincidencia perfecta.\n","En generaciÃ³n de texto libre, valores entre 0.02 y 0.10 son normales, ya que hay muchas formas vÃ¡lidas de decir lo mismo.\n","\n","**ROUGE-1, ROUGE-2, ROUGE-L:**\n","Miden la superposiciÃ³n de palabras (ROUGE-1), pares de palabras (ROUGE-2) y la subsecuencia comÃºn mÃ¡s larga (ROUGE-L) entre el texto generado y el real.\n","Valores entre 0.1 y 0.4 suelen ser razonables para generaciÃ³n de texto abierto.\n","\n","**Resultados obtenidos:**\n","BLEU promedio: 0.0421 (Â±0.0244)\n","\n","ROUGE-1 promedio: 0.2820 (Â±0.0970)\n","\n","ROUGE-2 promedio: 0.0505 (Â±0.0403)\n","\n","ROUGE-L promedio: 0.1764 (Â±0.0612)\n","\n","BLEU bajo es normal en generaciÃ³n de texto libre, porque el modelo puede generar frases correctas pero diferentes a la referencia.\n","ROUGE-1 y ROUGE-L muestran que hay una superposiciÃ³n razonable de palabras y frases entre lo generado y lo real.\n","ROUGE-2 es mÃ¡s bajo, lo que indica que la coincidencia de pares de palabras exactos es limitada, pero esto es esperable en tareas creativas."],"metadata":{"id":"mCaRbh18f23T"}},{"cell_type":"markdown","source":["# FunciÃ³n para cargar y usar el modelo entrenado:\n","En esta secciÃ³n se incluyen funciones para cargar un modelo previamente entrenado desde un archivo y para realizar inferencias (generar textos nuevos).\n","La funciÃ³n cargar_modelo_entrenado permite restaurar el modelo y sus pesos desde un checkpoint guardado, recuperando tambiÃ©n la configuraciÃ³n y el vocabulario.\n","La funciÃ³n demo_inferencia muestra cÃ³mo utilizar el modelo cargado para generar ejemplos de reseÃ±as a partir de diferentes categorÃ­as y subcategorÃ­as, demostrando el uso prÃ¡ctico del sistema en modo inferencia.\n"],"metadata":{"id":"k5Nn0NIvTglT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXAcdLoT0X_0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752604427900,"user_tz":240,"elapsed":738,"user":{"displayName":"Matias soto uribe","userId":"03140738076259130257"}},"outputId":"45e9014e-8e22-44bb-be20-51cc94bfc19d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ğŸ¯ MODO INFERENCIA - Ejemplos de uso\n","============================================================\n","\n","ğŸ“¦ TOPS\n","  â€¢ casual: love this little number ! the material is soft and the length is perfect for me . it is a bit of a baggy fit , but that ' s what makes it so fun\n","  â€¢ formal: i was really bummed about this top except for the price . it really is absolutely beautiful in person , and i couldn ' t bring myself to figure out how to wear it .\n","\n","ğŸ“¦ DRESSES\n","  â€¢ party: love this dress ! it is so comfy and fits as shown . i am 5 ' 9 \" and this dress hits me a little below the knee , but it is actually quite\n","  â€¢ casual: i bought this dress in the blue stripe . it ' s very flattering and comfy . it is a bit long ( i ' m 5 ' 1 ) but i love it nonetheless\n","\n","ğŸ“¦ SHOES\n","  â€¢ running: the first time i wore this , i got the blue color back and its a lovely shade of blue . it ' s not too see - through , a cami underneath is a\n","  â€¢ formal: great material . i really wanted to love this but unfortunately i will be returning it .\n"]}],"source":["# === FUNCIÃ“N PARA CARGAR Y USAR EL MODELO ENTRENADO ===\n","\n","def cargar_modelo_entrenado(ruta_modelo, dispositivo=DISPOSITIVO):\n","    \"\"\"\n","    Carga un modelo previamente entrenado desde un archivo checkpoint\n","    \"\"\"\n","    print(\"ğŸ“‚ Cargando modelo desde checkpoint...\")\n","\n","    # Cargar checkpoint\n","    checkpoint = torch.load(ruta_modelo, map_location=dispositivo)\n","\n","    # Extraer configuraciÃ³n\n","    config = checkpoint['config']\n","    tamaÃ±o_vocab = checkpoint['vocab_size']\n","\n","    # Recrear modelo\n","    modelo = ModeloGeneradorTexto(\n","        tamaÃ±o_vocabulario=tamaÃ±o_vocab,\n","        dim_modelo=config['dim_embedding'],\n","        num_cabezas=config['num_heads'],\n","        num_capas=config['num_layers'],\n","        dropout=config['dropout']\n","    ).to(dispositivo)\n","\n","    # Cargar pesos\n","    modelo.load_state_dict(checkpoint['model_state_dict'])\n","    modelo.eval()\n","\n","    print(f\"âœ… Modelo cargado exitosamente\")\n","    print(f\"   - Ã‰poca: {checkpoint['epoch']}\")\n","    print(f\"   - PÃ©rdida: {checkpoint['loss']:.4f}\")\n","    print(f\"   - Vocabulario: {tamaÃ±o_vocab} tokens\")\n","\n","    return modelo\n","\n","# Ejemplo de uso para inferencia\n","def demo_inferencia():\n","    \"\"\"\n","    DemostraciÃ³n de cÃ³mo usar el modelo para inferencia\n","    \"\"\"\n","    # Cargar modelo (descomentar cuando exista el archivo)\n","    # modelo_cargado = cargar_modelo_entrenado(RUTA_GUARDAR_MODELO)\n","\n","    print(\"\\nğŸ¯ MODO INFERENCIA - Ejemplos de uso\")\n","    print(\"=\" * 60)\n","\n","    # CategorÃ­as de ejemplo\n","    categorias_demo = {\n","        \"tops\": [\"casual\", \"formal\", \"summer\"],\n","        \"dresses\": [\"party\", \"casual\", \"wedding\"],\n","        \"shoes\": [\"running\", \"formal\", \"boots\"]\n","    }\n","\n","    # Generar ejemplos (usando el modelo actual del entrenamiento)\n","    for categoria_principal, subcategorias in categorias_demo.items():\n","        print(f\"\\nğŸ“¦ {categoria_principal.upper()}\")\n","        for sub in subcategorias[:2]:  # Solo 2 ejemplos por categorÃ­a\n","            prompt = f\"{sub} {categoria_principal}\"\n","            reseÃ±a = generar_texto_reseÃ±a(\n","                modelo_generativo,  # Cambiar a modelo_cargado cuando se use el checkpoint\n","                prompt,\n","                diccionario_vocabulario,\n","                longitud_max=35,\n","                temperatura=0.85,\n","                top_k=30\n","            )\n","            print(f\"  â€¢ {sub}: {reseÃ±a}\")\n","\n","# Ejecutar demostraciÃ³n\n","demo_inferencia()\n"]},{"cell_type":"markdown","source":["# ConclusiÃ³n\n","\n","El modelo Transformer entrenado para la generaciÃ³n de reseÃ±as ha mostrado un desempeÃ±o sÃ³lido y coherente. Durante el entrenamiento, la pÃ©rdida disminuyÃ³ de forma constante, indicando un buen aprendizaje. Los textos generados son naturales y relevantes para cada categorÃ­a, y la variaciÃ³n de la temperatura permite ajustar la creatividad de las respuestas.\n","\n","Las mÃ©tricas automÃ¡ticas (BLEU y ROUGE) se encuentran en rangos esperados para tareas de generaciÃ³n de texto libre, confirmando que el modelo no memoriza, sino que generaliza y produce reseÃ±as plausibles y variadas. En resumen, el sistema es robusto, versÃ¡til y estÃ¡ listo para ser utilizado en aplicaciones reales o como base para futuras mejoras."],"metadata":{"id":"fI4IdFuhTkpP"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}