{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Z4X8i7DJkIMc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752599780448,"user_tz":240,"elapsed":123983,"user":{"displayName":"Matias soto uribe","userId":"03140738076259130257"}},"outputId":"1bba0476-469f-4357-805b-7c4428f8c7ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","source":["# Importaciones\n","\n","**PyTorch (torch, nn, DataLoader):** Para crear y entrenar redes neuronales.\n","\n","**numpy, pandas:** Para manejar y analizar datos numéricos y tablas.\n","re, string, math: Para trabajar con texto y operaciones matemáticas.\n","\n","**collections:** Para contar y organizar datos fácilmente.\n","\n","**warnings:** Para ocultar advertencias.\n","\n","**nltk:** Para procesar y dividir texto en palabras.\n","\n","**BLEU y ROUGE:** Para evaluar la calidad de textos generados por el modelo.\n","\n","**subprocess:** Para instalar paquetes automáticamente si faltan."],"metadata":{"id":"49XJs7CDGSyb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lukrSIdSkJff"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import pandas as pd\n","import re\n","import string\n","import math\n","from collections import Counter, defaultdict\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Importaciones para métricas\n","import nltk\n","from nltk.tokenize import word_tokenize, RegexpTokenizer\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","try:\n","    from rouge_score import rouge_scorer\n","except ImportError:\n","    import subprocess\n","    subprocess.check_call(['pip', 'install', 'rouge-score'])\n","    from rouge_score import rouge_scorer\n","\n","# Descargas necesarias de NLTK\n","for package in ['punkt', 'punkt_tab', 'wordnet']:\n","    try:\n","        nltk.download(package, quiet=True)\n","    except:\n","        pass\n","\n","# Configuración de evaluación\n","smooth_function = SmoothingFunction().method2\n","evaluador_rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)"]},{"cell_type":"markdown","source":["# Definición de semilla reproductibilidad\n","\n","En este bloque se define y utiliza una función para establecer una semilla aleatoria fija en Python, NumPy y PyTorch. Esto asegura que los resultados de los experimentos sean reproducibles, es decir, que al ejecutar el código varias veces se obtengan los mismos resultados. También se configuran opciones adicionales para garantizar el determinismo en los cálculos y se fija la variable de entorno correspondiente.\n"],"metadata":{"id":"4vbQ11ggHpod"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1Hbmht90X_v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752599791883,"user_tz":240,"elapsed":20,"user":{"displayName":"Matias soto uribe","userId":"03140738076259130257"}},"outputId":"b7173e9d-c200-42a6-d064-1b2b9759a94c"},"outputs":[{"output_type":"stream","name":"stdout","text":["🌱 Semillas establecidas para reproducibilidad (semilla=42)\n"]}],"source":["# Definir semilla antes de usarla\n","SEMILLA_ALEATORIA = 42\n","\n","def establecer_semilla_reproducibilidad(semilla=42):\n","    \"\"\"\n","    Establece semillas aleatorias para reproducibilidad completa\n","    \"\"\"\n","    # Python\n","    import random\n","    random.seed(semilla)\n","\n","    # NumPy\n","    np.random.seed(semilla)\n","\n","    # PyTorch\n","    torch.manual_seed(semilla)\n","    torch.cuda.manual_seed(semilla)\n","    torch.cuda.manual_seed_all(semilla)\n","\n","    # Configuración adicional para determinismo\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","    # Variables de entorno\n","    import os\n","    os.environ['PYTHONHASHSEED'] = str(semilla)\n","\n","    print(f\"🌱 Semillas establecidas para reproducibilidad (semilla={semilla})\")\n","\n","# Establecer reproducibilidad\n","establecer_semilla_reproducibilidad(SEMILLA_ALEATORIA)\n"]},{"cell_type":"markdown","source":["# Definición de cada parametro de entrenamiento\n","\n","**DISPOSITIVO:**\n","Indica si se usará la GPU (\"cuda\") o la CPU para entrenar y ejecutar el modelo, dependiendo de la disponibilidad.\n","\n","**TAMAÑO_LOTE (batch size):**\n","Número de ejemplos que se procesan juntos en cada paso de entrenamiento. Un valor mayor puede acelerar el entrenamiento, pero requiere más memoria.\n","\n","**DIM_EMBEDDING:**\n","Dimensión de los vectores de embedding, es decir, el tamaño de la representación numérica de cada palabra o token.\n","\n","**CABEZAS_ATENCION:**\n","Número de \"cabezas\" en la capa de atención múltiple del Transformer. Más cabezas permiten al modelo enfocarse en diferentes partes de la secuencia simultáneamente.\n","\n","**CAPAS_TRANSFORMER:**\n","Cantidad de capas (bloques) del modelo Transformer. Más capas pueden aumentar la capacidad del modelo para aprender patrones complejos.\n","\n","**LONGITUD_MAXIMA:**\n","Longitud máxima permitida para las secuencias de entrada o salida. Las secuencias más largas se recortan o rellenan hasta este tamaño.\n","\n","**DROPOUT:**\n","Proporción de neuronas que se \"apagan\" aleatoriamente durante el entrenamiento para evitar el sobreajuste.\n","\n","**TASA_APRENDIZAJE (learning rate):**\n","Velocidad con la que el modelo ajusta sus parámetros durante el entrenamiento. Un valor adecuado es clave para un buen aprendizaje.\n","\n","**NUM_EPOCAS:**\n","Número de veces que el modelo recorre todo el conjunto de datos de entrenamiento.\n","\n","**FACTOR_GRAD_CLIP:**\n","Límite máximo para el valor de los gradientes durante el entrenamiento, evitando que sean demasiado grandes y causen inestabilidad.\n","\n","**UMBRAL_FRECUENCIA:**\n","Frecuencia mínima con la que una palabra debe aparecer en el corpus para ser incluida en el vocabulario del modelo."],"metadata":{"id":"BuJ_rUd7IF0V"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KbQWcYeskLFI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752599791957,"user_tz":240,"elapsed":34,"user":{"displayName":"Matias soto uribe","userId":"03140738076259130257"}},"outputId":"5ffd0386-9f22-45be-f305-89f39b6ef34a"},"outputs":[{"output_type":"stream","name":"stdout","text":["🚀 Dispositivo de procesamiento: cuda\n","📊 Configuración: 64 batch, 512 dim, 4 heads\n"]}],"source":["# === Parámetros del Sistema de Generación ===\n","\n","# Configuración del hardware\n","DISPOSITIVO = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Hiperparámetros del modelo\n","TAMAÑO_LOTE = 64\n","DIM_EMBEDDING = 512\n","CABEZAS_ATENCION = 4\n","CAPAS_TRANSFORMER = 3\n","LONGITUD_MAXIMA = 128\n","DROPOUT = 0.1\n","\n","# Parámetros de entrenamiento\n","TASA_APRENDIZAJE = 2e-4\n","NUM_EPOCAS = 45\n","FACTOR_GRAD_CLIP = 1.0\n","UMBRAL_FRECUENCIA = 3\n","\n","print(f\"🚀 Dispositivo de procesamiento: {DISPOSITIVO}\")\n","print(f\"📊 Configuración: {TAMAÑO_LOTE} batch, {DIM_EMBEDDING} dim, {CABEZAS_ATENCION} heads\")"]},{"cell_type":"markdown","source":["#Clase Vocabulario\n","\n","Esta clase se encarga de construir y gestionar el vocabulario del modelo. Permite convertir palabras o símbolos en índices numéricos y viceversa, lo cual es esencial para que el modelo pueda trabajar con texto.\n","\n","__init__: Inicializa el diccionario y el tokenizador.\n","\n","__len__: Devuelve cuántos tokens hay en el diccionario.\n","\n","**construir_diccionario:** Crea el vocabulario a partir de textos, solo con palabras frecuentes.\n","\n","**procesar_texto:** Limpia y divide el texto en tokens.\n","\n","**convertir_a_indices:** Convierte un texto en una lista de números (índices de tokens)."],"metadata":{"id":"0_xbk9pHIr8o"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6K89WIIkMPx"},"outputs":[],"source":["class DiccionarioTokens:\n","    def __init__(self, min_frecuencia=3):\n","        # Tokens especiales con diferentes símbolos\n","        self.indice_a_token = {\n","            0: \"[PAD]\",\n","            1: \"[INICIO]\",\n","            2: \"[FIN]\",\n","            3: \"[DESCONOCIDO]\",\n","            4: \">>>\"\n","        }\n","        self.token_a_indice = {v: k for k, v in self.indice_a_token.items()}\n","        self.min_frecuencia = min_frecuencia\n","        self.tokenizador = RegexpTokenizer(r'\\w+|[^\\w\\s]+')\n","\n","    def __len__(self):\n","        return len(self.indice_a_token)\n","\n","    def construir_diccionario(self, lista_textos):\n","        contador_palabras = Counter()\n","        indice_actual = len(self.indice_a_token)\n","\n","        # Primera pasada: contar frecuencias\n","        for texto in lista_textos:\n","            tokens = self.procesar_texto(texto)\n","            contador_palabras.update(tokens)\n","\n","        # Segunda pasada: agregar palabras frecuentes\n","        for palabra, frecuencia in contador_palabras.items():\n","            if frecuencia >= self.min_frecuencia and palabra not in self.token_a_indice:\n","                self.token_a_indice[palabra] = indice_actual\n","                self.indice_a_token[indice_actual] = palabra\n","                indice_actual += 1\n","\n","    def procesar_texto(self, texto):\n","        # Tokenización personalizada con regex\n","        texto = texto.lower().strip()\n","        tokens = self.tokenizador.tokenize(texto)\n","        return [t for t in tokens if t and not t.isspace()]\n","\n","    def convertir_a_indices(self, texto):\n","        tokens = self.procesar_texto(texto)\n","        desconocido_idx = self.token_a_indice[\"[DESCONOCIDO]\"]\n","        return [self.token_a_indice.get(token, desconocido_idx) for token in tokens]"]},{"cell_type":"markdown","source":["# clase ConjuntoDatosReseñas:\n","Esta clase prepara y organiza los datos de reseñas para entrenar el modelo. Lee un archivo CSV con reseñas y categorías, limpia los datos, construye el vocabulario necesario y convierte cada ejemplo en una secuencia de números (índices de tokens). Además, agrega tokens especiales, aplica padding para igualar la longitud de las secuencias y genera los pares de entrada y salida que necesita el modelo para aprender a predecir el siguiente token en una secuencia.\n","\n","\n","\n","*   __init__:\n","Carga los datos desde un archivo CSV, elimina filas vacías, crea el diccionario de tokens y prepara los textos combinando la categoría y la reseña.\n","\n","* __len__:\n","Devuelve cuántos ejemplos hay en el conjunto de datos.\n","\n","\n","*  __getitem__:\n","Toma una fila, la convierte en texto, la tokeniza y la transforma en una secuencia de índices con tokens especiales. Aplica padding y prepara los tensores de entrada y salida para el modelo.\n","\n","\n","\n","\n"],"metadata":{"id":"LzsCWmJjJnAB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_Ayo4R9kOdK"},"outputs":[],"source":["class ConjuntoDatosReseñas(Dataset):\n","    def __init__(self, archivo_csv, longitud_max=LONGITUD_MAXIMA):\n","        # Cargar y preparar datos\n","        self.datos = pd.read_csv(archivo_csv)\n","        self.datos = self.datos.dropna(subset=['Review Text', 'Class Name'])\n","        self.longitud_max = longitud_max\n","\n","        # Crear diccionario de tokens\n","        self.diccionario = DiccionarioTokens(min_frecuencia=UMBRAL_FRECUENCIA)\n","\n","        # Preparar textos combinados con separador diferente\n","        textos_completos = []\n","        for _, fila in self.datos.iterrows():\n","            categoria = str(fila['Class Name']).lower().strip()\n","            reseña = str(fila['Review Text']).lower().strip()\n","            texto_combinado = f\"{categoria} >>> {reseña}\"\n","            textos_completos.append(texto_combinado)\n","\n","        self.diccionario.construir_diccionario(textos_completos)\n","        print(f\"📖 Tamaño del vocabulario: {len(self.diccionario)}\")\n","\n","    def __len__(self):\n","        return len(self.datos)\n","\n","    def __getitem__(self, indice):\n","        fila = self.datos.iloc[indice]\n","        categoria = str(fila['Class Name']).lower().strip()\n","        reseña = str(fila['Review Text']).strip()\n","\n","        # Combinar con el nuevo separador\n","        texto_completo = f\"{categoria} >>> {reseña}\"\n","\n","        # Convertir a índices con tokens especiales\n","        indices = [self.diccionario.token_a_indice[\"[INICIO]\"]]\n","        indices.extend(self.diccionario.convertir_a_indices(texto_completo))\n","        indices.append(self.diccionario.token_a_indice[\"[FIN]\"])\n","\n","        # Aplicar padding\n","        tensor_padding = torch.zeros(self.longitud_max, dtype=torch.long)\n","        longitud_secuencia = min(len(indices), self.longitud_max)\n","        tensor_padding[:longitud_secuencia] = torch.tensor(indices[:longitud_secuencia])\n","\n","        # Preparar entrada y salida (shift by 1)\n","        entrada = tensor_padding[:-1]\n","        salida = tensor_padding[1:]\n","\n","        return entrada, salida"]},{"cell_type":"markdown","source":["# clase CodificacionPosicional:\n","Esta clase implementa la codificación posicional, una técnica esencial en los modelos Transformer para que el modelo sepa el orden de las palabras en una secuencia. Genera una matriz con valores basados en funciones seno y coseno, que se suma a los embeddings de las palabras. Así, cada posición en la secuencia tiene una representación única. Además, aplica dropout para ayudar a evitar el sobreajuste.\n","\n","\n","*   __init__:\n","Inicializa la clase, crea la matriz de codificación posicional usando funciones seno y coseno para cada posición y dimensión, y la guarda como un buffer (no se entrena).\n","\n","* **forward:**\n","Suma la codificación posicional a los embeddings de entrada y aplica dropout. Así, cada token tiene información sobre su posición en la secuencia.\n","\n"],"metadata":{"id":"GkqvkD-TKI0D"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WFa7m-yzkP0N"},"outputs":[],"source":["class CodificacionPosicional(nn.Module):\n","    def __init__(self, dimension_embed, longitud_max=LONGITUD_MAXIMA, base=10000):\n","        super().__init__()\n","        self.dimension_embed = dimension_embed\n","        self.dropout = nn.Dropout(DROPOUT)\n","\n","        # Crear matriz de codificación posicional\n","        matriz_pe = torch.zeros(longitud_max, dimension_embed)\n","        posiciones = torch.arange(0, longitud_max).unsqueeze(1).float()\n","\n","        # Calcular divisores para frecuencias\n","        indices_pares = torch.arange(0, dimension_embed, 2).float()\n","        divisor = torch.pow(base, indices_pares / dimension_embed)\n","\n","        # Aplicar funciones seno y coseno\n","        matriz_pe[:, 0::2] = torch.sin(posiciones / divisor)\n","        matriz_pe[:, 1::2] = torch.cos(posiciones / divisor)\n","\n","        # Registrar como buffer (no se entrena)\n","        self.register_buffer('codificacion_pos', matriz_pe.unsqueeze(0))\n","\n","    def forward(self, embeddings):\n","        # Agregar codificación posicional y aplicar dropout\n","        longitud_seq = embeddings.size(1)\n","        salida = embeddings + self.codificacion_pos[:, :longitud_seq, :]\n","        return self.dropout(salida)"]},{"cell_type":"markdown","source":["# clase ModeloGeneradorTexto:\n","Esta clase define el modelo generador de texto basado en la arquitectura Transformer. Incluye una capa de embeddings para convertir los tokens en vectores, una codificación posicional para indicar el orden de los tokens, y un decodificador Transformer compuesto por varias capas de atención y feedforward. El modelo utiliza máscaras causales para asegurar que cada posición solo pueda \"ver\" los tokens anteriores, lo que es esencial para la generación de texto. Finalmente, normaliza la salida y la proyecta al tamaño del vocabulario para predecir el siguiente token."],"metadata":{"id":"TrrIgD07Qjcn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xuDkV_NlkRHH"},"outputs":[],"source":["class ModeloGeneradorTexto(nn.Module):\n","    def __init__(self, tamaño_vocabulario, dim_modelo, num_cabezas, num_capas, dropout=DROPOUT):\n","        super().__init__()\n","\n","        # Capas de embedding\n","        self.capa_embedding = nn.Embedding(tamaño_vocabulario, dim_modelo)\n","        self.escala_embedding = math.sqrt(dim_modelo)\n","        self.codificador_posicion = CodificacionPosicional(dim_modelo)\n","\n","        # Configuración del decodificador transformer\n","        self.dropout_entrada = nn.Dropout(dropout)\n","        configuracion_capa = nn.TransformerDecoderLayer(\n","            d_model=dim_modelo,\n","            nhead=num_cabezas,\n","            dim_feedforward=dim_modelo * 4,\n","            dropout=dropout,\n","            activation='gelu',\n","            batch_first=True\n","        )\n","        self.decodificador = nn.TransformerDecoder(configuracion_capa, num_layers=num_capas)\n","\n","        # Capa de salida\n","        self.normalizacion_final = nn.LayerNorm(dim_modelo)\n","        self.proyeccion_salida = nn.Linear(dim_modelo, tamaño_vocabulario)\n","\n","        # Inicialización de pesos\n","        self._inicializar_pesos()\n","\n","    def _inicializar_pesos(self):\n","        # Inicialización Xavier para mejor convergencia\n","        for p in self.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p)\n","\n","    def crear_mascara_causal(self, tamaño):\n","        # Crear máscara triangular superior para atención causal\n","        mascara = torch.triu(torch.ones(tamaño, tamaño), diagonal=1)\n","        return mascara.bool().to(self.capa_embedding.weight.device)\n","\n","    def forward(self, tokens_entrada, mascara_padding=None):\n","        tamaño_secuencia = tokens_entrada.size(1)\n","\n","        # Embeddings con escalamiento\n","        embeddings = self.capa_embedding(tokens_entrada) * self.escala_embedding\n","        embeddings_con_pos = self.codificador_posicion(embeddings)\n","        embeddings_con_pos = self.dropout_entrada(embeddings_con_pos)\n","\n","        # Crear máscara causal\n","        mascara_atencion = self.crear_mascara_causal(tamaño_secuencia)\n","\n","        # Pasar por el decodificador\n","        salida_decodificador = self.decodificador(\n","            tgt=embeddings_con_pos,\n","            memory=embeddings_con_pos,\n","            tgt_mask=mascara_atencion,\n","            memory_mask=mascara_atencion,\n","            tgt_key_padding_mask=mascara_padding,\n","            memory_key_padding_mask=mascara_padding\n","        )\n","\n","        # Normalización y proyección final\n","        salida_normalizada = self.normalizacion_final(salida_decodificador)\n","        logits = self.proyeccion_salida(salida_normalizada)\n","\n","        return logits"]},{"cell_type":"markdown","source":["\n","\n","* __init__:\n","Inicializa todas las capas del modelo: embeddings, codificación posicional, decodificador Transformer, normalización y capa de salida. También prepara la inicialización de los pesos.\n","\n","* **_inicializar_pesos:**\n","Aplica la inicialización Xavier a los pesos del modelo para mejorar la convergencia durante el entrenamiento.\n","\n","* **crear_mascara_causal:**\n","Genera una máscara triangular que impide que el modelo vea tokens futuros durante la generación de texto (atención causal).\n","\n","* **forward:**\n","Define el paso hacia adelante del modelo: convierte los tokens en embeddings, suma la codificación posicional, aplica dropout, crea la máscara causal, pasa los datos por el decodificador y finalmente normaliza y proyecta la salida para obtener las predicciones.\n","\n"],"metadata":{"id":"T54rK_i-Q9nD"}},{"cell_type":"markdown","source":["# Función entrenar_epoca:\n","Esta función realiza una época completa de entrenamiento del modelo. Recorre los lotes de datos, mueve los tensores al dispositivo adecuado (CPU o GPU), crea la máscara de padding, realiza la predicción del modelo y calcula la pérdida. Además, implementa la acumulación de gradientes para optimizar el uso de memoria, aplica \"gradient clipping\" para evitar inestabilidades y actualiza los pesos del modelo con el optimizador. Al final, devuelve la pérdida promedio de la época."],"metadata":{"id":"_9atrijKRc1J"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vLtb-8c_kUF-"},"outputs":[],"source":["def entrenar_epoca(modelo, cargador_datos, optimizador, funcion_perdida, indice_pad, acumulacion_grad=1):\n","    modelo.train()\n","    perdida_acumulada = 0.0\n","    num_actualizaciones = 0\n","\n","    for batch_idx, (entrada, objetivo) in enumerate(cargador_datos):\n","        # Mover datos a dispositivo\n","        entrada = entrada.to(DISPOSITIVO)\n","        objetivo = objetivo.to(DISPOSITIVO)\n","\n","        # Crear máscara de padding\n","        mascara_padding = (entrada == indice_pad)\n","\n","        # Forward pass\n","        predicciones = modelo(entrada, mascara_padding)\n","\n","        # Calcular pérdida\n","        perdida = funcion_perdida(\n","            predicciones.reshape(-1, predicciones.size(-1)),\n","            objetivo.reshape(-1)\n","        )\n","\n","        # Normalizar pérdida para acumulación de gradientes\n","        perdida = perdida / acumulacion_grad\n","        perdida.backward()\n","\n","        # Actualizar pesos cada N pasos\n","        if (batch_idx + 1) % acumulacion_grad == 0:\n","            # Gradient clipping\n","            torch.nn.utils.clip_grad_norm_(modelo.parameters(), FACTOR_GRAD_CLIP)\n","\n","            # Paso del optimizador\n","            optimizador.step()\n","            optimizador.zero_grad()\n","            num_actualizaciones += 1\n","\n","        perdida_acumulada += perdida.item() * acumulacion_grad\n","\n","    return perdida_acumulada / len(cargador_datos)"]},{"cell_type":"markdown","source":["# Función generar_texto_reseña:\n","Esta función genera automáticamente una reseña de producto usando el modelo entrenado. Comienza con el tipo de producto y un separador especial, y va prediciendo palabra por palabra hasta alcanzar la longitud máxima o encontrar el token de fin. Utiliza técnicas de muestreo probabilístico (top-k y temperatura) para hacer la generación más variada y natural. Finalmente, decodifica los índices generados a texto, elimina los tokens especiales y devuelve solo la reseña generada."],"metadata":{"id":"uxgo_FgcSmLI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-kKcwvfPkYfK"},"outputs":[],"source":["def generar_texto_reseña(modelo, tipo_producto, diccionario, longitud_max=50, temperatura=1.0, top_k=50):\n","    modelo.eval()\n","\n","    # Preparar tokens iniciales\n","    texto_inicial = f\"{tipo_producto.lower()} >>>\"\n","    indices_tokens = [diccionario.token_a_indice[\"[INICIO]\"]]\n","    indices_tokens.extend(diccionario.convertir_a_indices(texto_inicial))\n","\n","    with torch.no_grad():\n","        for _ in range(longitud_max):\n","            # Preparar entrada\n","            tensor_entrada = torch.tensor(indices_tokens, dtype=torch.long).unsqueeze(0).to(DISPOSITIVO)\n","\n","            # Obtener predicciones\n","            salida = modelo(tensor_entrada)\n","            logits_siguiente = salida[0, -1, :] / temperatura\n","\n","            # Aplicar top-k sampling\n","            if top_k > 0:\n","                valores, indices = torch.topk(logits_siguiente, top_k)\n","                logits_siguiente[logits_siguiente < valores[-1]] = -float('Inf')\n","\n","            # Muestreo probabilístico\n","            probabilidades = F.softmax(logits_siguiente, dim=-1)\n","            token_predicho = torch.multinomial(probabilidades, 1).item()\n","\n","            indices_tokens.append(token_predicho)\n","\n","            # Verificar token de fin\n","            if token_predicho == diccionario.token_a_indice[\"[FIN]\"]:\n","                break\n","\n","    # Decodificar tokens a texto\n","    tokens_finales = indices_tokens[1:]  # Omitir [INICIO]\n","    if diccionario.token_a_indice[\"[FIN]\"] in tokens_finales:\n","        idx_fin = tokens_finales.index(diccionario.token_a_indice[\"[FIN]\"])\n","        tokens_finales = tokens_finales[:idx_fin]\n","\n","    # Convertir a palabras\n","    palabras = []\n","    for idx in tokens_finales:\n","        if idx in diccionario.indice_a_token:\n","            token = diccionario.indice_a_token[idx]\n","            if token not in [\"[INICIO]\", \"[FIN]\", \"[PAD]\"]:\n","                palabras.append(token)\n","\n","    texto_generado = ' '.join(palabras)\n","\n","    # Limpiar y retornar solo la reseña\n","    if \">>>\" in texto_generado:\n","        partes = texto_generado.split(\">>>\", 1)\n","        return partes[1].strip() if len(partes) > 1 else texto_generado\n","    return texto_generado"]},{"cell_type":"markdown","source":["# Función evaluar_calidad_generacion:\n","Esta función evalúa la calidad de los textos generados por el modelo utilizando métricas automáticas. Para varias muestras del conjunto de datos, genera un texto, lo compara con el texto real y calcula las métricas BLEU y ROUGE (ROUGE-1, ROUGE-2 y ROUGE-L), que miden la similitud entre el texto generado y el de referencia. Muestra los resultados de cada muestra y, al final, presenta un resumen con los promedios y desviaciones estándar de las métricas obtenidas."],"metadata":{"id":"UxB1U9-CSRcw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3rET_HJ4kZnK"},"outputs":[],"source":["def evaluar_calidad_generacion(modelo, conjunto_datos, diccionario, num_muestras=15, temperatura=0.8):\n","    # Listas para almacenar métricas\n","    metricas_bleu = []\n","    metricas_rouge1 = []\n","    metricas_rouge2 = []\n","    metricas_rougeL = []\n","\n","    print(\"🔍 Evaluando calidad del modelo generativo...\\n\")\n","\n","    for idx in range(min(num_muestras, len(conjunto_datos))):\n","        # Obtener datos de referencia\n","        tipo_articulo = conjunto_datos.datos.iloc[idx]['Class Name']\n","        texto_referencia = conjunto_datos.datos.iloc[idx]['Review Text']\n","\n","        # Generar texto\n","        texto_generado = generar_texto_reseña(\n","            modelo, tipo_articulo, diccionario,\n","            longitud_max=60, temperatura=temperatura\n","        )\n","\n","        # Tokenizar para BLEU\n","        tokens_referencia = word_tokenize(texto_referencia.lower())\n","        tokens_generados = word_tokenize(texto_generado.lower())\n","\n","        # Calcular BLEU\n","        puntuacion_bleu = sentence_bleu(\n","            [tokens_referencia],\n","            tokens_generados,\n","            smoothing_function=smooth_function\n","        )\n","\n","        # Calcular ROUGE\n","        puntuaciones_rouge = evaluador_rouge.score(texto_referencia, texto_generado)\n","\n","        # Almacenar métricas\n","        metricas_bleu.append(puntuacion_bleu)\n","        metricas_rouge1.append(puntuaciones_rouge['rouge1'].fmeasure)\n","        metricas_rouge2.append(puntuaciones_rouge['rouge2'].fmeasure)\n","        metricas_rougeL.append(puntuaciones_rouge['rougeL'].fmeasure)\n","\n","        # Mostrar resultados\n","        print(f\"📝 Muestra {idx+1}/{num_muestras}\")\n","        print(f\"   Categoría: {tipo_articulo}\")\n","        print(f\"   BLEU: {puntuacion_bleu:.3f} | R-1: {puntuaciones_rouge['rouge1'].fmeasure:.3f} | R-2: {puntuaciones_rouge['rouge2'].fmeasure:.3f} | R-L: {puntuaciones_rouge['rougeL'].fmeasure:.3f}\")\n","        print(f\"   Referencia: {texto_referencia[:100]}...\")\n","        print(f\"   Generado: {texto_generado[:100]}...\")\n","        print(\"-\" * 80)\n","\n","    # Estadísticas finales\n","    print(\"\\n📊 RESUMEN DE MÉTRICAS\")\n","    print(\"=\" * 50)\n","    print(f\"BLEU promedio:    {np.mean(metricas_bleu):.4f} (±{np.std(metricas_bleu):.4f})\")\n","    print(f\"ROUGE-1 promedio: {np.mean(metricas_rouge1):.4f} (±{np.std(metricas_rouge1):.4f})\")\n","    print(f\"ROUGE-2 promedio: {np.mean(metricas_rouge2):.4f} (±{np.std(metricas_rouge2):.4f})\")\n","    print(f\"ROUGE-L promedio: {np.mean(metricas_rougeL):.4f} (±{np.std(metricas_rougeL):.4f})\")\n","\n","    return {\n","        'bleu': metricas_bleu,\n","        'rouge1': metricas_rouge1,\n","        'rouge2': metricas_rouge2,\n","        'rougeL': metricas_rougeL\n","    }"]},{"cell_type":"markdown","source":["# Entrenamiento del Modelo\n","\n","En este bloque se realiza toda la preparación y ejecución del proceso de entrenamiento del modelo generador de texto. Se cargan los datos desde un archivo CSV, se construye el conjunto de datos y el dataloader, y se configura el vocabulario. Luego, se inicializa el modelo Transformer, el optimizador, el scheduler para ajustar la tasa de aprendizaje y la función de pérdida con suavizado de etiquetas.\n","\n","A continuación, se ejecuta el bucle de entrenamiento durante varias épocas, mostrando el progreso, la pérdida y el tiempo de cada época. El modelo se guarda automáticamente cuando mejora la pérdida, y cada cierto número de épocas se generan ejemplos de texto para monitorear la calidad del modelo."],"metadata":{"id":"SyoAs9pPSzxy"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mDNXHEh2kbC8","executionInfo":{"status":"ok","timestamp":1752604421466,"user_tz":240,"elapsed":4629221,"user":{"displayName":"Matias soto uribe","userId":"03140738076259130257"}},"outputId":"4419ec03-a88b-4a18-ad4c-cda78756b37d"},"outputs":[{"output_type":"stream","name":"stdout","text":["📁 Cargando conjunto de datos...\n","✓ Total de registros encontrados: 23486\n","📖 Tamaño del vocabulario: 6709\n","📚 Tamaño del vocabulario construido: 6709\n","🔢 Total de lotes por época: 354\n","\n","🏗️ Construyendo arquitectura del modelo...\n","📊 Total de parámetros: 19,489,845\n","📊 Parámetros entrenables: 19,489,845\n","\n","🚀 INICIANDO PROCESO DE ENTRENAMIENTO\n","============================================================\n","📈 Época 1/45 | Pérdida: 5.2344 | LR: 0.000200 | Tiempo: 95.1s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 2/45 | Pérdida: 4.4949 | LR: 0.000199 | Tiempo: 98.6s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 3/45 | Pérdida: 4.2863 | LR: 0.000198 | Tiempo: 101.0s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 4/45 | Pérdida: 4.1594 | LR: 0.000197 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 5/45 | Pérdida: 4.0694 | LR: 0.000195 | Tiempo: 101.8s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 6/45 | Pérdida: 3.9973 | LR: 0.000192 | Tiempo: 101.7s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 7/45 | Pérdida: 3.9362 | LR: 0.000189 | Tiempo: 101.9s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 8/45 | Pérdida: 3.8829 | LR: 0.000186 | Tiempo: 101.8s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 9/45 | Pérdida: 3.8346 | LR: 0.000183 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 10/45 | Pérdida: 3.7912 | LR: 0.000179 | Tiempo: 101.6s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","\n","🎯 Generando muestras de ejemplo:\n","   • tops: i really liked this top when i tried it on . i ' m 5 ' 4 \", 145 lbs . the small ...\n","   • jeans: these jeans are perfect . they are flattering and fit well ....\n","   • shoes: i love the look of this piece . it is so cute and easy to wear . i am 5 ' 2 \" an...\n","📈 Época 11/45 | Pérdida: 3.7505 | LR: 0.000175 | Tiempo: 101.8s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 12/45 | Pérdida: 3.7118 | LR: 0.000170 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 13/45 | Pérdida: 3.6757 | LR: 0.000165 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 14/45 | Pérdida: 3.6407 | LR: 0.000160 | Tiempo: 101.6s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 15/45 | Pérdida: 3.6075 | LR: 0.000155 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 16/45 | Pérdida: 3.5774 | LR: 0.000149 | Tiempo: 101.6s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 17/45 | Pérdida: 3.5467 | LR: 0.000144 | Tiempo: 101.6s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 18/45 | Pérdida: 3.5164 | LR: 0.000138 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 19/45 | Pérdida: 3.4881 | LR: 0.000132 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 20/45 | Pérdida: 3.4614 | LR: 0.000126 | Tiempo: 101.8s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","\n","🎯 Generando muestras de ejemplo:\n","   • tops: i love this vest . it ' s soft and can be dressed up or down . it ' s very flatt...\n","   • jeans: i have a few pairs of these jeans from last year and love them . they fit my fir...\n","   • shoes: i ' m so glad i bought this . i absolutely adore this outfit ! it has the right ...\n","📈 Época 21/45 | Pérdida: 3.4358 | LR: 0.000119 | Tiempo: 101.7s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 22/45 | Pérdida: 3.4103 | LR: 0.000113 | Tiempo: 101.7s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 23/45 | Pérdida: 3.3871 | LR: 0.000107 | Tiempo: 101.8s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 24/45 | Pérdida: 3.3639 | LR: 0.000101 | Tiempo: 101.8s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 25/45 | Pérdida: 3.3419 | LR: 0.000094 | Tiempo: 101.7s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 26/45 | Pérdida: 3.3215 | LR: 0.000088 | Tiempo: 101.9s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 27/45 | Pérdida: 3.3029 | LR: 0.000082 | Tiempo: 102.0s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 28/45 | Pérdida: 3.2839 | LR: 0.000076 | Tiempo: 102.0s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 29/45 | Pérdida: 3.2666 | LR: 0.000071 | Tiempo: 102.0s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 30/45 | Pérdida: 3.2505 | LR: 0.000065 | Tiempo: 102.1s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","\n","🎯 Generando muestras de ejemplo:\n","   • tops: this is a really cute piece . i love the length and the color . i ' m 5 ' 1 \" an...\n","   • jeans: i love these jeans ! i ordered them in size 26 and they fit perfectly ! they are...\n","   • shoes: i was so excited to get this in the mail . unfortunately the fit was so off . it...\n","📈 Época 31/45 | Pérdida: 3.2348 | LR: 0.000060 | Tiempo: 101.8s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 32/45 | Pérdida: 3.2202 | LR: 0.000055 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 33/45 | Pérdida: 3.2080 | LR: 0.000050 | Tiempo: 101.6s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 34/45 | Pérdida: 3.1959 | LR: 0.000045 | Tiempo: 101.7s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 35/45 | Pérdida: 3.1840 | LR: 0.000041 | Tiempo: 101.7s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 36/45 | Pérdida: 3.1738 | LR: 0.000037 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 37/45 | Pérdida: 3.1642 | LR: 0.000034 | Tiempo: 101.6s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 38/45 | Pérdida: 3.1556 | LR: 0.000031 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 39/45 | Pérdida: 3.1472 | LR: 0.000028 | Tiempo: 101.7s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 40/45 | Pérdida: 3.1409 | LR: 0.000025 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","\n","🎯 Generando muestras de ejemplo:\n","   • tops: i love this top . i was able to arrive in an xs , and it was too large on me , a...\n","   • jeans: i tried on the regular size in the store in the regular size 27 ( 5 ' 3 \", 110lb...\n","   • shoes: i loved this online and ordered it in both colors . i am usually a small but ord...\n","📈 Época 41/45 | Pérdida: 3.1347 | LR: 0.000023 | Tiempo: 101.6s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 42/45 | Pérdida: 3.1293 | LR: 0.000022 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 43/45 | Pérdida: 3.1227 | LR: 0.000021 | Tiempo: 101.6s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 44/45 | Pérdida: 3.1191 | LR: 0.000020 | Tiempo: 101.6s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","📈 Época 45/45 | Pérdida: 3.1146 | LR: 0.000020 | Tiempo: 101.5s\n","   ✨ Nueva mejor pérdida! Guardando modelo...\n","\n","✅ ENTRENAMIENTO COMPLETADO\n","🏆 Mejor pérdida alcanzada: 3.1146\n"]}],"source":["# === CONFIGURACIÓN DEL SISTEMA DE ENTRENAMIENTO ===\n","\n","# Rutas de archivos\n","RUTA_DATOS = \"/content/drive/MyDrive/ET_deep_learning/Reviews.csv\"\n","RUTA_GUARDAR_MODELO = \"/content/drive/MyDrive/ET_deep_learning/modelo_generativo_v2.pth\"\n","\n","# Verificar disponibilidad de datos\n","print(\"📁 Cargando conjunto de datos...\")\n","datos_brutos = pd.read_csv(RUTA_DATOS)\n","print(f\"✓ Total de registros encontrados: {len(datos_brutos)}\")\n","\n","# Crear dataset y dataloader\n","conjunto_entrenamiento = ConjuntoDatosReseñas(RUTA_DATOS)\n","cargador_entrenamiento = DataLoader(\n","    conjunto_entrenamiento,\n","    batch_size=TAMAÑO_LOTE,\n","    shuffle=True,\n","    num_workers=2 if DISPOSITIVO.type == 'cuda' else 0,\n","    pin_memory=True if DISPOSITIVO.type == 'cuda' else False\n",")\n","\n","# Configuración del vocabulario\n","diccionario_vocabulario = conjunto_entrenamiento.diccionario\n","indice_padding = diccionario_vocabulario.token_a_indice[\"[PAD]\"]\n","tamaño_vocabulario = len(diccionario_vocabulario)\n","\n","print(f\"📚 Tamaño del vocabulario construido: {tamaño_vocabulario}\")\n","print(f\"🔢 Total de lotes por época: {len(cargador_entrenamiento)}\")\n","\n","# === INICIALIZACIÓN DEL MODELO ===\n","print(\"\\n🏗️ Construyendo arquitectura del modelo...\")\n","modelo_generativo = ModeloGeneradorTexto(\n","    tamaño_vocabulario=tamaño_vocabulario,\n","    dim_modelo=DIM_EMBEDDING,\n","    num_cabezas=CABEZAS_ATENCION,\n","    num_capas=CAPAS_TRANSFORMER,\n","    dropout=DROPOUT\n",").to(DISPOSITIVO)\n","\n","# Contar parámetros\n","total_parametros = sum(p.numel() for p in modelo_generativo.parameters())\n","parametros_entrenables = sum(p.numel() for p in modelo_generativo.parameters() if p.requires_grad)\n","print(f\"📊 Total de parámetros: {total_parametros:,}\")\n","print(f\"📊 Parámetros entrenables: {parametros_entrenables:,}\")\n","\n","# Configuración del optimizador con scheduler\n","optimizador = torch.optim.AdamW(\n","    modelo_generativo.parameters(),\n","    lr=TASA_APRENDIZAJE,\n","    betas=(0.9, 0.98),\n","    eps=1e-9,\n","    weight_decay=0.01\n",")\n","\n","# Learning rate scheduler\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n","    optimizador,\n","    T_max=NUM_EPOCAS,\n","    eta_min=TASA_APRENDIZAJE * 0.1\n",")\n","\n","# Función de pérdida con label smoothing\n","criterio_perdida = nn.CrossEntropyLoss(\n","    ignore_index=indice_padding,\n","    label_smoothing=0.1\n",")\n","\n","# === BUCLE DE ENTRENAMIENTO ===\n","print(\"\\n🚀 INICIANDO PROCESO DE ENTRENAMIENTO\")\n","print(\"=\" * 60)\n","\n","historial_perdidas = []\n","mejor_perdida = float('inf')\n","\n","for epoca in range(1, NUM_EPOCAS + 1):\n","    tiempo_inicio = torch.cuda.Event(enable_timing=True) if DISPOSITIVO.type == 'cuda' else None\n","    tiempo_fin = torch.cuda.Event(enable_timing=True) if DISPOSITIVO.type == 'cuda' else None\n","\n","    if tiempo_inicio:\n","        tiempo_inicio.record()\n","\n","    # Entrenar una época\n","    perdida_epoca = entrenar_epoca(\n","        modelo_generativo,\n","        cargador_entrenamiento,\n","        optimizador,\n","        criterio_perdida,\n","        indice_padding\n","    )\n","\n","    historial_perdidas.append(perdida_epoca)\n","\n","    # Actualizar learning rate\n","    scheduler.step()\n","    lr_actual = scheduler.get_last_lr()[0]\n","\n","    if tiempo_fin:\n","        tiempo_fin.record()\n","        torch.cuda.synchronize()\n","        tiempo_epoca = tiempo_inicio.elapsed_time(tiempo_fin) / 1000.0\n","    else:\n","        tiempo_epoca = 0\n","\n","    # Mostrar progreso\n","    print(f\"📈 Época {epoca}/{NUM_EPOCAS} | Pérdida: {perdida_epoca:.4f} | LR: {lr_actual:.6f} | Tiempo: {tiempo_epoca:.1f}s\")\n","\n","    # Guardar mejor modelo\n","    if perdida_epoca < mejor_perdida:\n","        mejor_perdida = perdida_epoca\n","        print(f\"   ✨ Nueva mejor pérdida! Guardando modelo...\")\n","        torch.save({\n","            'epoch': epoca,\n","            'model_state_dict': modelo_generativo.state_dict(),\n","            'optimizer_state_dict': optimizador.state_dict(),\n","            'loss': perdida_epoca,\n","            'vocab_size': tamaño_vocabulario,\n","            'config': {\n","                'dim_embedding': DIM_EMBEDDING,\n","                'num_heads': CABEZAS_ATENCION,\n","                'num_layers': CAPAS_TRANSFORMER,\n","                'dropout': DROPOUT\n","            }\n","        }, RUTA_GUARDAR_MODELO)\n","\n","    # Generar muestras cada 10 épocas\n","    if epoca % 10 == 0:\n","        print(\"\\n🎯 Generando muestras de ejemplo:\")\n","        for categoria in [\"tops\", \"jeans\", \"shoes\"]:\n","            texto_muestra = generar_texto_reseña(modelo_generativo, categoria, diccionario_vocabulario, temperatura=0.7)\n","            print(f\"   • {categoria}: {texto_muestra[:80]}...\")\n","\n","print(\"\\n✅ ENTRENAMIENTO COMPLETADO\")\n","print(f\"🏆 Mejor pérdida alcanzada: {mejor_perdida:.4f}\")"]},{"cell_type":"markdown","source":["\n","Cantidad de datos:\n","El modelo fue entrenado con 23,486 registros y un vocabulario de 6,709 tokens. Esto es un tamaño considerable, lo que ayuda a que el modelo generalice mejor.\n","\n","Parámetros:\n","El modelo tiene 19,489,845 parámetros entrenables, lo que indica una arquitectura robusta y capaz de aprender patrones complejos.\n","\n","Pérdida (Loss):\n","La pérdida inicial en la primera época fue de 5.2344.\n","La pérdida fue disminuyendo de manera constante en cada época, lo que es una señal de que el modelo está aprendiendo correctamente.\n","La mejor pérdida alcanzada fue de 3.1146 en la última época (45/45).\n","Cada vez que la pérdida mejoró, el modelo fue guardado automáticamente."],"metadata":{"id":"IkobKPldfBz_"}},{"cell_type":"markdown","source":["# Fase de evaluación y generación:\n","En esta sección se evalúa el modelo entrenado y se generan ejemplos de reseñas. Primero, se generan textos para diferentes categorías y temperaturas, mostrando cómo varía la creatividad del modelo según el parámetro de temperatura. Luego, se realiza una evaluación automática del modelo usando métricas como BLEU y ROUGE sobre varias muestras, y se presentan estadísticas detalladas (percentiles, mínimo y máximo) de los resultados obtenidos. Finalmente, se muestra un resumen con información relevante sobre el modelo, el vocabulario y el dispositivo utilizado."],"metadata":{"id":"tmPiyzWOTTew"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ts51gJFkc1M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752604427161,"user_tz":240,"elapsed":5692,"user":{"displayName":"Matias soto uribe","userId":"03140738076259130257"}},"outputId":"38b76f87-ef11-432c-d90b-55e615d67e6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🎨 GENERACIÓN DE EJEMPLOS DE RESEÑAS\n","============================================================\n","\n","📝 Generando reseñas con diferentes temperaturas:\n","\n","\n","🌡️ Temperatura = 0.5\n","----------------------------------------\n","📦 BLOUSES:\n","   i just received this top in the mail and i love it . i am 5 ' 2 \", 120 lbs and 34b and i got the xs . i could probably have gone with an xxs , but i\n","\n","📦 DRESSES:\n","   this dress is beautiful and fits true to size . i am 5 ' 5 \" and about 120 lbs . i ordered a 4 petite and it fits perfectly . i can ' t wait to wear it !\n","\n","📦 PANTS:\n","   i love these pants , they are so comfortable , and stylish . i am 5 ' 10 \", and the length is perfect for me . they are the perfect length for me , they are not too long\n","\n","\n","🌡️ Temperatura = 0.8\n","----------------------------------------\n","📦 BLOUSES:\n","   i love this top . i bought it in both the black and white colors . i thought it would be a great top to wear for work or play . i did size up because i have broad shoulders\n","\n","📦 DRESSES:\n","   the color and cut of this dress are gorgeous , but the fit was so tight . i would have kept it if it weren ' t the cut or the dress was correctly on me . maybe i '\n","\n","📦 PANTS:\n","   i love the cut and style of this jumpsuit . it is so flattering and can be worn on or off shoulder .\n","\n","\n","🌡️ Temperatura = 1.0\n","----------------------------------------\n","📦 BLOUSES:\n","   this top is absolutely fabulous . i wore it for work and received tons of compliments !\n","\n","📦 DRESSES:\n","   so glad i saw this online -- i read the previous reviews of the dress and decided to get it . sadly , the dress is [DESCONOCIDO] of a [DESCONOCIDO] review so i purchased it before i ordered it .\n","\n","📦 PANTS:\n","   i bought the white jumpsuit as a gift for a friend . she loved it . it was a favorite . it is comfortable , easy and very flattering .\n","\n","\n","\n","🔬 EVALUACIÓN DETALLADA DEL MODELO\n","============================================================\n","🔍 Evaluando calidad del modelo generativo...\n","\n","📝 Muestra 1/20\n","   Categoría: Intimates\n","   BLEU: 0.022 | R-1: 0.063 | R-2: 0.000 | R-L: 0.063\n","   Referencia: Absolutely wonderful - silky and sexy and comfortable...\n","   Generado: i knew this chemise would be a must - have been a summer staple in the past year . it can be a great...\n","--------------------------------------------------------------------------------\n","📝 Muestra 2/20\n","   Categoría: Dresses\n","   BLEU: 0.063 | R-1: 0.458 | R-2: 0.121 | R-L: 0.254\n","   Referencia: Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never...\n","   Generado: i just received this dress and i ' m very happy with it . i have taken such a to fit and look great ...\n","--------------------------------------------------------------------------------\n","📝 Muestra 3/20\n","   Categoría: Dresses\n","   BLEU: 0.023 | R-1: 0.274 | R-2: 0.028 | R-L: 0.164\n","   Referencia: I had such high hopes for this dress and really wanted it to work for me. i initially ordered the pe...\n","   Generado: i ordered this dress in the navy and love it . the fit is perfect - not too long , not too short or ...\n","--------------------------------------------------------------------------------\n","📝 Muestra 4/20\n","   Categoría: Pants\n","   BLEU: 0.036 | R-1: 0.189 | R-2: 0.028 | R-L: 0.135\n","   Referencia: I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothin...\n","   Generado: this jumpsuit is great ! great quality and construction ! the top is a bit wide but a little too sho...\n","--------------------------------------------------------------------------------\n","📝 Muestra 5/20\n","   Categoría: Blouses\n","   BLEU: 0.039 | R-1: 0.211 | R-2: 0.000 | R-L: 0.140\n","   Referencia: This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to we...\n","   Generado: love it ! i usually wear a small , but only had to get a medium in this top ! great fall / winter sh...\n","--------------------------------------------------------------------------------\n","📝 Muestra 6/20\n","   Categoría: Dresses\n","   BLEU: 0.036 | R-1: 0.336 | R-2: 0.027 | R-L: 0.188\n","   Referencia: I love tracy reese dresses, but this one is not for the very petite. i am just under 5 feet tall and...\n","   Generado: this dress is even better in person . i am 5 ' description and ordered the petite size . it hits at ...\n","--------------------------------------------------------------------------------\n","📝 Muestra 7/20\n","   Categoría: Knits\n","   BLEU: 0.009 | R-1: 0.167 | R-2: 0.031 | R-L: 0.106\n","   Referencia: I aded this in my basket at hte last mintue to see what it would look like in person. (store pick up...\n","   Generado: i was looking for a casual , yet cute top for the spring . runs large , and i normally wear a medium...\n","--------------------------------------------------------------------------------\n","📝 Muestra 8/20\n","   Categoría: Knits\n","   BLEU: 0.020 | R-1: 0.276 | R-2: 0.013 | R-L: 0.171\n","   Referencia: I ordered this in carbon for store pick up, and had a ton of stuff (as always) to try on and used th...\n","   Generado: i bought this shirt in the green color . i like that it ' s not too thin and it ' s not see through ...\n","--------------------------------------------------------------------------------\n","📝 Muestra 9/20\n","   Categoría: Dresses\n","   BLEU: 0.069 | R-1: 0.434 | R-2: 0.123 | R-L: 0.265\n","   Referencia: I love this dress. i usually get an xs but it runs a little snug in bust so i ordered up a size. ver...\n","   Generado: tried this on in the store . i ' m 5 ' 4 \", 130lbs , 34 / b . i usually wear a size s . i ordered an...\n","--------------------------------------------------------------------------------\n","📝 Muestra 10/20\n","   Categoría: Dresses\n","   BLEU: 0.067 | R-1: 0.429 | R-2: 0.113 | R-L: 0.270\n","   Referencia: I'm 5\"5' and 125 lbs. i ordered the s petite to make sure the length wasn't too long. i typically we...\n","   Generado: i love this dress so much ! i ' m 5 ' 0 \" and the petite length of the dress fits just right ! i lov...\n","--------------------------------------------------------------------------------\n","📝 Muestra 11/20\n","   Categoría: Dresses\n","   BLEU: 0.017 | R-1: 0.182 | R-2: 0.023 | R-L: 0.114\n","   Referencia: Dress runs small esp where the zipper area runs. i ordered the sp which typically fits me and it was...\n","   Generado: i love this dress ! it is so cute on ! i wore it to a wedding and then i received so many compliment...\n","--------------------------------------------------------------------------------\n","📝 Muestra 12/20\n","   Categoría: Dresses\n","   BLEU: 0.090 | R-1: 0.303 | R-2: 0.129 | R-L: 0.303\n","   Referencia: This dress is perfection! so pretty and flattering....\n","   Generado: this dress is so comfortable and versatile on . i love the detail in the back and the detail . i am ...\n","--------------------------------------------------------------------------------\n","📝 Muestra 13/20\n","   Categoría: Dresses\n","   BLEU: 0.027 | R-1: 0.252 | R-2: 0.054 | R-L: 0.146\n","   Referencia: More and more i find myself reliant on the reviews written by savvy shoppers before me and for the m...\n","   Generado: i tried this dress on for my sister ' s birthday and she loved it ! she actually returned it and the...\n","--------------------------------------------------------------------------------\n","📝 Muestra 14/20\n","   Categoría: Intimates\n","   BLEU: 0.034 | R-1: 0.279 | R-2: 0.033 | R-L: 0.213\n","   Referencia: Bought the black xs to go under the larkspur midi dress because they didn't bother lining the skirt ...\n","   Generado: i am a 32dd and the medium fits perfectly . the colors are beautiful and the material is very comfor...\n","--------------------------------------------------------------------------------\n","📝 Muestra 15/20\n","   Categoría: Dresses\n","   BLEU: 0.036 | R-1: 0.290 | R-2: 0.042 | R-L: 0.152\n","   Referencia: This is a nice choice for holiday gatherings. i like that the length grazes the knee so it is conser...\n","   Generado: this dress is very pretty and is true to size . i ' m 5 ' 11 \" and this falls to my ankles ... which...\n","--------------------------------------------------------------------------------\n","📝 Muestra 16/20\n","   Categoría: Pants\n","   BLEU: 0.034 | R-1: 0.282 | R-2: 0.041 | R-L: 0.134\n","   Referencia: I took these out of the package and wanted them to fit so badly, but i could tell before i put them ...\n","   Generado: this is a very comfortable romper that has a unique design to it and is well made . however , it is ...\n","--------------------------------------------------------------------------------\n","📝 Muestra 17/20\n","   Categoría: Pants\n","   BLEU: 0.020 | R-1: 0.218 | R-2: 0.020 | R-L: 0.139\n","   Referencia: Material and color is nice.  the leg opening is very large.  i am 5'1 (100#) and the length hits me ...\n","   Generado: these pants are so cute . i ' m 5 ' 8 \" and the regular length is perfect . they fit great , are fla...\n","--------------------------------------------------------------------------------\n","📝 Muestra 18/20\n","   Categoría: Blouses\n","   BLEU: 0.034 | R-1: 0.289 | R-2: 0.045 | R-L: 0.156\n","   Referencia: Took a chance on this blouse and so glad i did. i wasn't crazy about how the blouse is photographed ...\n","   Generado: i am so glad i purchased this top ! it is great with a pair of jeans or slacks for work . it will be...\n","--------------------------------------------------------------------------------\n","📝 Muestra 19/20\n","   Categoría: Outerwear\n","   BLEU: 0.098 | R-1: 0.289 | R-2: 0.049 | R-L: 0.169\n","   Referencia: A flattering, super cozy coat.  will work well for cold, dry days and will look good with jeans or a...\n","   Generado: i bought this coat in the store , size small . i am 5 ' 4 \" 125 and 130lbs , i bought the size small...\n","--------------------------------------------------------------------------------\n","📝 Muestra 20/20\n","   Categoría: Dresses\n","   BLEU: 0.070 | R-1: 0.421 | R-2: 0.089 | R-L: 0.246\n","   Referencia: I love the look and feel of this tulle dress. i was looking for something different, but not over th...\n","   Generado: i got this dress in the mail and was so thrilled with the fit and feel of the fabric . however , i p...\n","--------------------------------------------------------------------------------\n","\n","📊 RESUMEN DE MÉTRICAS\n","==================================================\n","BLEU promedio:    0.0421 (±0.0244)\n","ROUGE-1 promedio: 0.2820 (±0.0970)\n","ROUGE-2 promedio: 0.0505 (±0.0403)\n","ROUGE-L promedio: 0.1764 (±0.0612)\n","\n","\n","📊 ANÁLISIS ESTADÍSTICO ADICIONAL\n","============================================================\n","\n","BLEU:\n","  - P25: 0.0230\n","  - P50 (mediana): 0.0350\n","  - P75: 0.0641\n","  - Min: 0.0092\n","  - Max: 0.0981\n","\n","ROUGE1:\n","  - P25: 0.2160\n","  - P50 (mediana): 0.2803\n","  - P75: 0.3112\n","  - Min: 0.0635\n","  - Max: 0.4576\n","\n","ROUGE2:\n","  - P25: 0.0262\n","  - P50 (mediana): 0.0371\n","  - P75: 0.0626\n","  - Min: 0.0000\n","  - Max: 0.1290\n","\n","ROUGEL:\n","  - P25: 0.1377\n","  - P50 (mediana): 0.1600\n","  - P75: 0.2212\n","  - Min: 0.0635\n","  - Max: 0.3030\n","\n","\n","✨ PROCESO COMPLETADO EXITOSAMENTE ✨\n","📁 Modelo guardado en: /content/drive/MyDrive/ET_deep_learning/modelo_generativo_v2.pth\n","📊 Vocabulario final: 6709 tokens\n","⚡ Dispositivo utilizado: cuda\n","\n","🎉 ¡Gracias por usar este sistema de generación de reseñas!\n"]}],"source":["# === FASE DE EVALUACIÓN Y GENERACIÓN ===\n","\n","print(\"\\n🎨 GENERACIÓN DE EJEMPLOS DE RESEÑAS\")\n","print(\"=\" * 60)\n","\n","# Lista de categorías para probar\n","categorias_prueba = [\"blouses\", \"dresses\", \"pants\", \"sweaters\", \"jackets\"]\n","\n","print(\"\\n📝 Generando reseñas con diferentes temperaturas:\\n\")\n","\n","for temperatura in [0.5, 0.8, 1.0]:\n","    print(f\"\\n🌡️ Temperatura = {temperatura}\")\n","    print(\"-\" * 40)\n","\n","    for categoria in categorias_prueba[:3]:  # Solo las primeras 3 para demostración\n","        reseña_generada = generar_texto_reseña(\n","            modelo_generativo,\n","            categoria,\n","            diccionario_vocabulario,\n","            longitud_max=40,\n","            temperatura=temperatura,\n","            top_k=40\n","        )\n","        print(f\"📦 {categoria.upper()}:\")\n","        print(f\"   {reseña_generada}\\n\")\n","\n","# === EVALUACIÓN COMPLETA DEL MODELO ===\n","print(\"\\n\\n🔬 EVALUACIÓN DETALLADA DEL MODELO\")\n","print(\"=\" * 60)\n","\n","# Evaluar con métricas automáticas\n","resultados_metricas = evaluar_calidad_generacion(\n","    modelo_generativo,\n","    conjunto_entrenamiento,\n","    diccionario_vocabulario,\n","    num_muestras=20,\n","    temperatura=0.8\n",")\n","\n","# Visualización adicional\n","print(\"\\n\\n📊 ANÁLISIS ESTADÍSTICO ADICIONAL\")\n","print(\"=\" * 60)\n","\n","# Calcular percentiles\n","for metrica, valores in resultados_metricas.items():\n","    p25 = np.percentile(valores, 25)\n","    p50 = np.percentile(valores, 50)\n","    p75 = np.percentile(valores, 75)\n","    print(f\"\\n{metrica.upper()}:\")\n","    print(f\"  - P25: {p25:.4f}\")\n","    print(f\"  - P50 (mediana): {p50:.4f}\")\n","    print(f\"  - P75: {p75:.4f}\")\n","    print(f\"  - Min: {min(valores):.4f}\")\n","    print(f\"  - Max: {max(valores):.4f}\")\n","\n","# Mensaje final\n","print(\"\\n\\n✨ PROCESO COMPLETADO EXITOSAMENTE ✨\")\n","print(f\"📁 Modelo guardado en: {RUTA_GUARDAR_MODELO}\")\n","print(f\"📊 Vocabulario final: {tamaño_vocabulario} tokens\")\n","print(f\"⚡ Dispositivo utilizado: {DISPOSITIVO}\")\n","print(\"\\n🎉 ¡Gracias por usar este sistema de generación de reseñas!\")"]},{"cell_type":"markdown","source":["**¿Qué miden estas métricas?**\n","\n","**BLEU:**\n","Mide la coincidencia de n-gramas (palabras o secuencias de palabras) entre el texto generado y el de referencia.\n","\n","**0:** Nada coincide, 1: Coincidencia perfecta.\n","En generación de texto libre, valores entre 0.02 y 0.10 son normales, ya que hay muchas formas válidas de decir lo mismo.\n","\n","**ROUGE-1, ROUGE-2, ROUGE-L:**\n","Miden la superposición de palabras (ROUGE-1), pares de palabras (ROUGE-2) y la subsecuencia común más larga (ROUGE-L) entre el texto generado y el real.\n","Valores entre 0.1 y 0.4 suelen ser razonables para generación de texto abierto.\n","\n","**Resultados obtenidos:**\n","BLEU promedio: 0.0421 (±0.0244)\n","\n","ROUGE-1 promedio: 0.2820 (±0.0970)\n","\n","ROUGE-2 promedio: 0.0505 (±0.0403)\n","\n","ROUGE-L promedio: 0.1764 (±0.0612)\n","\n","BLEU bajo es normal en generación de texto libre, porque el modelo puede generar frases correctas pero diferentes a la referencia.\n","ROUGE-1 y ROUGE-L muestran que hay una superposición razonable de palabras y frases entre lo generado y lo real.\n","ROUGE-2 es más bajo, lo que indica que la coincidencia de pares de palabras exactos es limitada, pero esto es esperable en tareas creativas."],"metadata":{"id":"mCaRbh18f23T"}},{"cell_type":"markdown","source":["# Función para cargar y usar el modelo entrenado:\n","En esta sección se incluyen funciones para cargar un modelo previamente entrenado desde un archivo y para realizar inferencias (generar textos nuevos).\n","La función cargar_modelo_entrenado permite restaurar el modelo y sus pesos desde un checkpoint guardado, recuperando también la configuración y el vocabulario.\n","La función demo_inferencia muestra cómo utilizar el modelo cargado para generar ejemplos de reseñas a partir de diferentes categorías y subcategorías, demostrando el uso práctico del sistema en modo inferencia.\n"],"metadata":{"id":"k5Nn0NIvTglT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXAcdLoT0X_0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752604427900,"user_tz":240,"elapsed":738,"user":{"displayName":"Matias soto uribe","userId":"03140738076259130257"}},"outputId":"45e9014e-8e22-44bb-be20-51cc94bfc19d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🎯 MODO INFERENCIA - Ejemplos de uso\n","============================================================\n","\n","📦 TOPS\n","  • casual: love this little number ! the material is soft and the length is perfect for me . it is a bit of a baggy fit , but that ' s what makes it so fun\n","  • formal: i was really bummed about this top except for the price . it really is absolutely beautiful in person , and i couldn ' t bring myself to figure out how to wear it .\n","\n","📦 DRESSES\n","  • party: love this dress ! it is so comfy and fits as shown . i am 5 ' 9 \" and this dress hits me a little below the knee , but it is actually quite\n","  • casual: i bought this dress in the blue stripe . it ' s very flattering and comfy . it is a bit long ( i ' m 5 ' 1 ) but i love it nonetheless\n","\n","📦 SHOES\n","  • running: the first time i wore this , i got the blue color back and its a lovely shade of blue . it ' s not too see - through , a cami underneath is a\n","  • formal: great material . i really wanted to love this but unfortunately i will be returning it .\n"]}],"source":["# === FUNCIÓN PARA CARGAR Y USAR EL MODELO ENTRENADO ===\n","\n","def cargar_modelo_entrenado(ruta_modelo, dispositivo=DISPOSITIVO):\n","    \"\"\"\n","    Carga un modelo previamente entrenado desde un archivo checkpoint\n","    \"\"\"\n","    print(\"📂 Cargando modelo desde checkpoint...\")\n","\n","    # Cargar checkpoint\n","    checkpoint = torch.load(ruta_modelo, map_location=dispositivo)\n","\n","    # Extraer configuración\n","    config = checkpoint['config']\n","    tamaño_vocab = checkpoint['vocab_size']\n","\n","    # Recrear modelo\n","    modelo = ModeloGeneradorTexto(\n","        tamaño_vocabulario=tamaño_vocab,\n","        dim_modelo=config['dim_embedding'],\n","        num_cabezas=config['num_heads'],\n","        num_capas=config['num_layers'],\n","        dropout=config['dropout']\n","    ).to(dispositivo)\n","\n","    # Cargar pesos\n","    modelo.load_state_dict(checkpoint['model_state_dict'])\n","    modelo.eval()\n","\n","    print(f\"✅ Modelo cargado exitosamente\")\n","    print(f\"   - Época: {checkpoint['epoch']}\")\n","    print(f\"   - Pérdida: {checkpoint['loss']:.4f}\")\n","    print(f\"   - Vocabulario: {tamaño_vocab} tokens\")\n","\n","    return modelo\n","\n","# Ejemplo de uso para inferencia\n","def demo_inferencia():\n","    \"\"\"\n","    Demostración de cómo usar el modelo para inferencia\n","    \"\"\"\n","    # Cargar modelo (descomentar cuando exista el archivo)\n","    # modelo_cargado = cargar_modelo_entrenado(RUTA_GUARDAR_MODELO)\n","\n","    print(\"\\n🎯 MODO INFERENCIA - Ejemplos de uso\")\n","    print(\"=\" * 60)\n","\n","    # Categorías de ejemplo\n","    categorias_demo = {\n","        \"tops\": [\"casual\", \"formal\", \"summer\"],\n","        \"dresses\": [\"party\", \"casual\", \"wedding\"],\n","        \"shoes\": [\"running\", \"formal\", \"boots\"]\n","    }\n","\n","    # Generar ejemplos (usando el modelo actual del entrenamiento)\n","    for categoria_principal, subcategorias in categorias_demo.items():\n","        print(f\"\\n📦 {categoria_principal.upper()}\")\n","        for sub in subcategorias[:2]:  # Solo 2 ejemplos por categoría\n","            prompt = f\"{sub} {categoria_principal}\"\n","            reseña = generar_texto_reseña(\n","                modelo_generativo,  # Cambiar a modelo_cargado cuando se use el checkpoint\n","                prompt,\n","                diccionario_vocabulario,\n","                longitud_max=35,\n","                temperatura=0.85,\n","                top_k=30\n","            )\n","            print(f\"  • {sub}: {reseña}\")\n","\n","# Ejecutar demostración\n","demo_inferencia()\n"]},{"cell_type":"markdown","source":["# Conclusión\n","\n","El modelo Transformer entrenado para la generación de reseñas ha mostrado un desempeño sólido y coherente. Durante el entrenamiento, la pérdida disminuyó de forma constante, indicando un buen aprendizaje. Los textos generados son naturales y relevantes para cada categoría, y la variación de la temperatura permite ajustar la creatividad de las respuestas.\n","\n","Las métricas automáticas (BLEU y ROUGE) se encuentran en rangos esperados para tareas de generación de texto libre, confirmando que el modelo no memoriza, sino que generaliza y produce reseñas plausibles y variadas. En resumen, el sistema es robusto, versátil y está listo para ser utilizado en aplicaciones reales o como base para futuras mejoras."],"metadata":{"id":"fI4IdFuhTkpP"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}