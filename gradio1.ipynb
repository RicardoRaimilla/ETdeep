{"cells":[{"cell_type":"markdown","metadata":{"id":"F5Vj8APdNWPu"},"source":["# 游녱 Clasificador y Generador de Rese침as de Prendas\n","\n","Este sistema combina visi칩n por computador y procesamiento de lenguaje natural para:\n","\n","- 游댌 **Clasificar una prenda de ropa** en una de 15 categor칤as usando un modelo RexNet-150.\n","- 九꽲잺 **Generar una rese침a autom치tica** usando un Transformer entrenado con descripciones reales.\n","- 游깷 **Interfaz Gradio** para subir im치genes y ver resultados en tiempo real.\n","\n","### 游 Componentes:\n","- **Clasificador RexNet-150** (`modelo_final.pth`): predice clases como `Blazer`, `Jeans`, `Polo`, etc.\n","- **Generador Transformer** (`modelo_generativo_v2.pth`): crea una rese침a basada en la clase predicha.\n","- **Vocabulario**: reconstruido desde `Reviews.csv`.\n","\n","### 丘뙖잺 Proceso:\n","1. Se sube una imagen.\n","2. Se clasifica la prenda con RexNet.\n","3. Se genera una rese침a usando el Transformer.\n","4. Se muestra todo en una interfaz Gradio.\n","\n","游늸 Ideal para sistemas de recomendaci칩n de ropa y cat치logos inteligentes.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":32628,"status":"aborted","timestamp":1752619524513,"user":{"displayName":"RICARDO . RAIMILLA VARGAS","userId":"08657465817151240640"},"user_tz":240},"id":"l_DlVC5ZMyX9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://492f517066e25ef57a.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\u003cdiv\u003e\u003ciframe src=\"https://492f517066e25ef57a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Created dataset file at: .gradio/flagged/dataset1.csv\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2191, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1702, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 894, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"/tmp/ipython-input-4-3097303433.py\", line 153, in predecir\n","    imagen = transform(imagen).unsqueeze(0).to(DEVICE)\n","             ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n","    img = t(img)\n","          ^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\", line 354, in forward\n","    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\", line 465, in resize\n","    _, image_height, image_width = get_dimensions(img)\n","                                   ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\", line 80, in get_dimensions\n","    return F_pil.get_dimensions(img)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_pil.py\", line 31, in get_dimensions\n","    raise TypeError(f\"Unexpected type {type(img)}\")\n","TypeError: Unexpected type \u003cclass 'NoneType'\u003e\n"]}],"source":["# === IMPORTS ===\n","import gradio as gr\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import timm\n","from PIL import Image\n","import pandas as pd\n","import math\n","from collections import Counter\n","import re\n","from nltk.tokenize import RegexpTokenizer\n","import os\n","\n","# === SETUP ===\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","EMBED_SIZE = 512\n","NUM_HEADS = 4\n","NUM_LAYERS = 3\n","MAX_LEN = 128\n","DROPOUT = 0.1\n","\n","# === CLASSES ===\n","CLOTHING_CLASSES = [\n","    'Blazer', 'Celana_Panjang', 'Celana_Pendek', 'Gaun', 'Hoodie',\n","    'Jaket', 'Jaket_Denim', 'Jaket_Olahraga', 'Jeans', 'Kaos',\n","    'Kemeja', 'Mantel', 'Polo', 'Rok', 'Sweter'\n","]\n","\n","# === TOKENIZER \u0026 VOCAB ===\n","class DiccionarioTokens:\n","    def __init__(self, min_frecuencia=3):\n","        self.indice_a_token = {0: \"[PAD]\", 1: \"[INICIO]\", 2: \"[FIN]\", 3: \"[DESCONOCIDO]\", 4: \"\u003e\u003e\u003e\"}\n","        self.token_a_indice = {v: k for k, v in self.indice_a_token.items()}\n","        self.min_frecuencia = min_frecuencia\n","        self.tokenizador = RegexpTokenizer(r'\\w+|[^\\w\\s]+')\n","\n","    def __len__(self):\n","        return len(self.indice_a_token)\n","\n","    def construir_diccionario(self, lista_textos):\n","        contador = Counter()\n","        idx = len(self.indice_a_token)\n","        for texto in lista_textos:\n","            for token in self.procesar_texto(texto):\n","                contador[token] += 1\n","                if contador[token] \u003e= self.min_frecuencia and token not in self.token_a_indice:\n","                    self.token_a_indice[token] = idx\n","                    self.indice_a_token[idx] = token\n","                    idx += 1\n","\n","    def procesar_texto(self, texto):\n","        texto = texto.lower().strip()\n","        return [t for t in self.tokenizador.tokenize(texto) if t and not t.isspace()]\n","\n","    def convertir_a_indices(self, texto):\n","        tokens = self.procesar_texto(texto)\n","        unk = self.token_a_indice[\"[DESCONOCIDO]\"]\n","        return [self.token_a_indice.get(t, unk) for t in tokens]\n","\n","# === POSITIONAL ENCODING ===\n","class CodificacionPosicional(nn.Module):\n","    def __init__(self, dim, max_len=MAX_LEN):\n","        super().__init__()\n","        pe = torch.zeros(max_len, dim)\n","        pos = torch.arange(0, max_len).unsqueeze(1).float()\n","        div = torch.exp(torch.arange(0, dim, 2).float() * (-math.log(10000.0) / dim))\n","        pe[:, 0::2] = torch.sin(pos / div)\n","        pe[:, 1::2] = torch.cos(pos / div)\n","        self.register_buffer('codificacion_pos', pe.unsqueeze(0))\n","\n","    def forward(self, x):\n","        x = x + self.codificacion_pos[:, :x.size(1), :]\n","        return x\n","\n","# === TRANSFORMER ===\n","class ModeloGeneradorTexto(nn.Module):\n","    def __init__(self, tama침o_vocabulario, dim_modelo, num_cabezas, num_capas):\n","        super().__init__()\n","        self.capa_embedding = nn.Embedding(tama침o_vocabulario, dim_modelo)\n","        self.escala_embedding = math.sqrt(dim_modelo)\n","        self.codificador_posicion = CodificacionPosicional(dim_modelo)\n","        capa_decoder = nn.TransformerDecoderLayer(\n","            d_model=dim_modelo, nhead=num_cabezas, dim_feedforward=dim_modelo*4,\n","            dropout=DROPOUT, activation='gelu', batch_first=True\n","        )\n","        self.decodificador = nn.TransformerDecoder(capa_decoder, num_layers=num_capas)\n","        self.normalizacion_final = nn.LayerNorm(dim_modelo)\n","        self.proyeccion_salida = nn.Linear(dim_modelo, tama침o_vocabulario)\n","\n","    def crear_mascara_causal(self, tam):\n","        return torch.triu(torch.ones(tam, tam), diagonal=1).bool().to(DEVICE)\n","\n","    def forward(self, tokens_entrada):\n","        emb = self.capa_embedding(tokens_entrada) * self.escala_embedding\n","        emb = self.codificador_posicion(emb)\n","        mascara = self.crear_mascara_causal(tokens_entrada.size(1))\n","        dec = self.decodificador(tgt=emb, memory=emb, tgt_mask=mascara)\n","        dec = self.normalizacion_final(dec)\n","        return self.proyeccion_salida(dec)\n","\n","# === FUNCIONES AUXILIARES ===\n","def crear_vocab():\n","    df = pd.read_csv(\"/content/drive/MyDrive/ET deep learning/Reviews.csv\")\n","    df = df.dropna(subset=['Review Text', 'Class Name'])\n","    textos = df['Class Name'].str.lower() + \" \u003e\u003e\u003e \" + df['Review Text'].str.lower()\n","    vocab = DiccionarioTokens(min_frecuencia=3)\n","    vocab.construir_diccionario(textos.tolist())\n","    return vocab\n","\n","def generar_rese침a(modelo, clase, vocab, max_len=30):\n","    modelo.eval()\n","    tokens = [vocab.token_a_indice[\"[INICIO]\"]] + vocab.convertir_a_indices(f\"{clase.lower()} \u003e\u003e\u003e\")\n","    with torch.no_grad():\n","        for _ in range(max_len):\n","            entrada = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(DEVICE)\n","            salida = modelo(entrada)\n","            next_token = torch.argmax(salida[0, -1]).item()\n","            tokens.append(next_token)\n","            if next_token == vocab.token_a_indice[\"[FIN]\"]:\n","                break\n","    tokens = tokens[1:]  # quitar [INICIO]\n","    texto = \" \".join(vocab.indice_a_token[t] for t in tokens if t not in [vocab.token_a_indice[\"[FIN]\"], vocab.token_a_indice[\"[INICIO]\"]])\n","    return texto.split(\"\u003e\u003e\u003e\")[-1].strip()\n","\n","# === LOAD MODELS ===\n","def cargar_modelos():\n","    vocab = crear_vocab()\n","\n","    # RexNet\n","    cnn_path = \"/content/drive/MyDrive/ET deep learning/modelo_final2.pth\"\n","    rexnet = timm.create_model(\"rexnet_150\", pretrained=False, num_classes=len(CLOTHING_CLASSES))\n","    rexnet.load_state_dict(torch.load(cnn_path, map_location=DEVICE))\n","    rexnet = rexnet.to(DEVICE).eval()\n","\n","    # Transformer\n","    transformer_path = \"/content/drive/MyDrive/ET deep learning/modelo_generativo_v2.pth\"\n","    checkpoint = torch.load(transformer_path, map_location=DEVICE)\n","    transformer = ModeloGeneradorTexto(len(vocab), EMBED_SIZE, NUM_HEADS, NUM_LAYERS)\n","    transformer.load_state_dict(checkpoint[\"model_state_dict\"])\n","    transformer = transformer.to(DEVICE).eval()\n","\n","    return rexnet, transformer, vocab\n","\n","# === INFERENCIA ===\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","def predecir(imagen):\n","    imagen = transform(imagen).unsqueeze(0).to(DEVICE)\n","    with torch.no_grad():\n","        out = rexnet(imagen)\n","        probs = torch.nn.functional.softmax(out, dim=1)\n","        idx = torch.argmax(probs, dim=1).item()\n","        clase = CLOTHING_CLASSES[idx]\n","        confianza = probs[0, idx].item()\n","        rese침a = generar_rese침a(transformer, clase, vocab)\n","    return clase, f\"{confianza:.2%}\", rese침a\n","\n","# === EJECUCI칍N ===\n","rexnet, transformer, vocab = cargar_modelos()\n","\n","demo = gr.Interface(\n","    fn=predecir,\n","    inputs=gr.Image(type=\"pil\"),\n","    outputs=[\n","        gr.Textbox(label=\"Clase de Prenda\"),\n","        gr.Textbox(label=\"Confianza\"),\n","        gr.Textbox(label=\"Rese침a Generada\")\n","    ],\n","    title=\"Clasificador de Prendas + Rese침as Transformer\",\n","    description=\"Sube una imagen y obt칠n la clase de prenda + rese침a generada\"\n",")\n","\n","demo.launch(share=True, debug=True)\n"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}